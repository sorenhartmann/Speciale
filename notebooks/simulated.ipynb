{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from hydra.utils import instantiate\n",
    "from typing import Tuple\n",
    "import seaborn as sns\n",
    "from src.utils import Run, EXPERIMENT_PATH\n",
    "from src.analysis.sample_distribution import load_samples\n",
    "from src.analysis.simulated import (\n",
    "    get_exact_posterior, \n",
    "    plot_sampled_joint_bivariate,\n",
    "    plot_sampled_distributions_pairs, \n",
    "    )\n",
    "import torch\n",
    "from src.analysis.colors import get_color, get_colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_poly(x, coeffs):\n",
    "    return coeffs[0] + sum(c*x**i for i, c in enumerate(coeffs[1:], start=1))\n",
    "    \n",
    "run_dirs = (EXPERIMENT_PATH /\"simulated\"/\"2021-12-16\"/\"13-27-43\").glob(\"[0-9]\")\n",
    "runs = [Run(x) for x in run_dirs]\n",
    "dataset = instantiate(runs[0].cfg.data.dataset)\n",
    "X, Y = dataset[:]\n",
    "xx = torch.linspace(-3, 3)\n",
    "plt.plot(xx, eval_poly(xx, dataset.coeffs), \"--k\")\n",
    "plt.scatter(X[:, 1], Y[:, 0]) \n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$P(x)$\")\n",
    "sns.despine()\n",
    "plt.savefig(\"../thesis/Figures/pol_model.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = get_exact_posterior(X, Y)\n",
    "pal = ColorPalette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    if \"sampler\" not in run.cfg[\"inference\"]:\n",
    "        continue\n",
    "\n",
    "    sample_data = load_samples(run)\n",
    "    sampler,  batch_size = sample_data.index[0][:2]\n",
    "    color = pal.get_color(run)\n",
    "    kwargs = {\"exact_posterior\": posterior, \"sample_data\": sample_data, \"color\": color}\n",
    "    plot_sampled_distributions_pairs(**kwargs)\n",
    "    plt.savefig(f\"../thesis/Figures/simulated_pairs_{sampler}_{batch_size}.pdf\")\n",
    "    plot_sampled_joint_bivariate(i=1, j=3, xlims=(-2.5, 1.0), ylims=(0.1, 0.5), **kwargs)\n",
    "    plt.savefig(f\"../thesis/Figures/simulated_joint_{sampler}_{batch_size}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 1\n",
    "# j = 3\n",
    "# joint_plots = {}\n",
    "\n",
    "# xlims = (-2.5, 1.0)\n",
    "# ylims = (0.1, 0.5)\n",
    "\n",
    "# # for key, data in sample_data[[i, j]].groupby(level=[0, 1]):\n",
    "#     with (sns.color_palette(PLOT_COLORS[key][\"color_palette\"])):\n",
    "#         joint_plots[key] = plot_sampled_joint_bivariate(\n",
    "#             data, exact_posterior=posterior, xlims=xlims, ylims=ylims\n",
    "#         )\n",
    "#         plt.savefig(f\"../thesis/Figures/simulated_joint_{'_'.join(map(str, key))}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "def load_var_params(file_name):\n",
    "    state_dict = torch.load(file_name)[\"state_dict\"]\n",
    "    mu = state_dict[\"model.linear.variational_parameters.weight.mu\"].flatten().numpy()\n",
    "    rho = state_dict[\"model.linear.variational_parameters.weight.rho\"]\n",
    "    sigma = rho.exp().log1p().flatten().numpy()\n",
    "    return pd.DataFrame({\"mu\": mu, \"sigma\": sigma}).rename_axis(\"parameter\")\n",
    "\n",
    "vi_run = next(r for r in runs if \"Variational\" in r.cfg.inference._target_)\n",
    "vi_ckpt = next(vi_run._dir.glob(\"**/*.ckpt\"))\n",
    "var_params = load_var_params(vi_ckpt)\n",
    "var_distribution = MultivariateNormal(\n",
    "    torch.tensor(var_params[\"mu\"]),\n",
    "    torch.diag(torch.tensor(var_params[\"sigma\"])).square(),\n",
    ")\n",
    "color = pal.get_color(vi_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal, MultivariateNormal\n",
    "from itertools import product\n",
    "from src.analysis.simulated import (\n",
    "    draw_bi_gaussian,\n",
    "    draw_uni_gaussian,\n",
    "    get_marginal,\n",
    "    get_lims,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 8))\n",
    "levels = [1e-2, 1e-1, 1e0, 1e1, 1e2]\n",
    "\n",
    "for i, j in product(range(4), repeat=2):\n",
    "    plt.sca(axes[i, j])\n",
    "    if i == j:\n",
    "        true_marg = get_marginal(posterior, i)\n",
    "        var_marg = get_marginal(var_distribution, i)\n",
    "        xlim = get_lims(true_marg.mean, true_marg.stddev)\n",
    "        lines = []\n",
    "        lines += draw_uni_gaussian(true_marg, xlim=xlim, color=\"black\")\n",
    "        lines += draw_uni_gaussian(var_marg, xlim=xlim, color=color)\n",
    "        plt.xlim(xlim)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        true_marg = get_marginal(posterior, i, j)\n",
    "        var_marg = get_marginal(var_distribution, i, j)\n",
    "        xlim = get_lims(true_marg.mean[0], true_marg.stddev[0])\n",
    "        ylim = get_lims(true_marg.mean[1], true_marg.stddev[1])\n",
    "        draw_bi_gaussian(true_marg, xlim, ylim, colors=\"black\", levels=levels)\n",
    "        draw_bi_gaussian(var_marg, xlim, ylim, colors=[color], levels=levels)\n",
    "        plt.xlim(xlim)\n",
    "        plt.ylim(ylim)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.xlabel(j)\n",
    "\n",
    "    if j == 0:\n",
    "        plt.ylabel(i)\n",
    "plt.figlegend(\n",
    "    lines,\n",
    "    [\"True posterior\", \"Variational posterior\"],\n",
    "    loc=\"lower center\",\n",
    "    ncol=2,\n",
    "    labelspacing=0,\n",
    "    frameon=False,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.09)\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(\"../thesis/Figures/vi-simulated.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predidictions = pd.DataFrame(\n",
    "    (X @ torch.tensor(sample_data.values).view(-1, 4, 1)).squeeze().numpy()\n",
    ").set_index(sample_data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ci_low(x):\n",
    "    return x.quantile(0.05)\n",
    "def ci_high(x):\n",
    "    return x.quantile(0.95)\n",
    "def median(x):\n",
    "    return x.quantile(0.5)\n",
    "\n",
    "predidictions = (\n",
    "    pd.DataFrame(\n",
    "        (X @ torch.tensor(sample_data.values).view(-1, 4, 1)).squeeze().numpy()\n",
    "    )\n",
    "    .set_index(sample_data.index)\n",
    "    # .melt(ignore_index=False)\n",
    "    .groupby(level=[\"sampler\", \"batch_size\"])\n",
    "    .agg([\"mean\", \"std\", ci_low, \"median\", ci_high])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predidictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.distributions import Normal\n",
    "\n",
    "\n",
    "# def draw_uni_variational(x, **kwargs):\n",
    "\n",
    "#     i = x.name\n",
    "#     marg = get_marginal(posterior, i)\n",
    "#     xlims = marg.mean + torch.tensor([-5, 5]) * marg.stddev\n",
    "#     xx = torch.linspace(*xlims)\n",
    "#     yy = marg.log_prob(xx).exp()\n",
    "\n",
    "#     batch_sizes = (\n",
    "#         x.index.get_level_values(level=\"batch_size\")\n",
    "#         .unique()\n",
    "#         .sort_values(ascending=False)\n",
    "#     )\n",
    "#     def get_densities(data):\n",
    "#         print(data)\n",
    "\n",
    "#     x.groupby(level=\"batch_sizes\")\n",
    "\n",
    "#     sns.lineplot(x=xx, y=yy, color=\"black\")\n",
    "\n",
    "#     mu = torch.tensor(x[\"mu\"].values).view(2, 1)\n",
    "#     sigma = torch.tensor(x[\"sigma\"].values).view(2, 1)\n",
    "#     var_dist = Normal(mu, sigma)\n",
    "\n",
    "#     pd.DataFrame().assign(\n",
    "#         batch_size=x.get,\n",
    "#     )\n",
    "\n",
    "#     d = x.copy()\n",
    "\n",
    "\n",
    "# def draw_bi_variational(x, **kwargs):\n",
    "\n",
    "#     i = x.name\n",
    "#     marg = get_marginal(posterior, i)\n",
    "#     xlims = marg.mean + torch.tensor([-5, 5]) * marg.stddev\n",
    "#     xx = torch.linspace(*xlims)\n",
    "#     yy = marg.log_prob(xx).exp()\n",
    "#     sns.lineplot(x=xx, y=yy)\n",
    "\n",
    "\n",
    "# pg: sns.PairGrid = (\n",
    "#     variational_models.rename_axis(\"var_param\", axis=1)\n",
    "#     .unstack(\"batch_size\")\n",
    "#     .transpose()\n",
    "#     .pipe((sns.PairGrid, \"data\"), vars=[0, 1, 2, 3])\n",
    "# )\n",
    "# pg.map_diag(draw_uni_variational, size=\"batch_size\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "for r in run.runs:\n",
    "    model = instantiate(r.config[\"model\"])\n",
    "    \n",
    "\n",
    "\n",
    "# n_samples = 10_000\n",
    "# param_samples = posterior.sample((n_samples,))\n",
    "# XX = torch.stack([torch.ones_like(xx), xx, xx**2, xx**3]).T\n",
    "# predictions = XX @ param_samples.unsqueeze(-1)\n",
    "# (\n",
    "#     pd.DataFrame(predictions.squeeze().numpy(), columns=XX[:, 1].numpy())\n",
    "#     .melt(\n",
    "#         var_name=\"x\",\n",
    "#         value_name=\"y\",\n",
    "#     )\n",
    "#     .groupby(\"x\")\n",
    "#     ç\n",
    "#     .unstack()\n",
    "#     .droplevel(0, axis=\"columns\")\n",
    "#     .reset_index()\n",
    "#     .melt(\n",
    "#         id_vars=\"x\",\n",
    "#         var_name=\"quantile\",\n",
    "#     )\n",
    "#     .pipe((sns.relplot, \"data\"), x=\"x\", y=\"value\", hue=\"quantile\", kind=\"line\")\n",
    "# )\n",
    "# plt.scatter(X[:,1], y)\n",
    "# plt.plot(xx, eval_poly(xx, coeffs))\n",
    "# plt.plot(xx, eval_poly(xx, sgd_inf.model.linear.weight.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d767b8386092d7cf7d2b9cae3bbc1311fb6c0ac52cead8f221dab1753f4d4fb8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
