{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from src.experiments.common import Experiment\n",
    "import torch\n",
    "from hydra.utils import instantiate\n",
    "from src.inference.mcmc import MCMCInference\n",
    "from src.inference.mcmc.samplers import HMC\n",
    "import matplotlib.pyplot as plt\n",
    "from src.models.linear import LinearRegressor\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from src.bayesian.prior_sets import get_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_poly(x, coeffs):\n",
    "    return coeffs[0] + sum(c*x**i for i, c in enumerate(coeffs[1:], start=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Experiment(\"simulated\").latest_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = instantiate(run.runs[0].config.data.dataset)\n",
    "X, Y = dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.linspace(-3, 3)\n",
    "plt.plot(xx, eval_poly(xx, dataset.coeffs))\n",
    "plt.scatter(X[:, 1], Y[:, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_0 = torch.eye(4)\n",
    "mu_0 = torch.zeros(4)\n",
    "ols = (X.T @ X).inverse() @ X.T @ Y.squeeze()\n",
    "L_n =  X.T @ X + L_0\n",
    "mu_n = L_n.inverse() @ (X.T @ X @ ols + L_0 @ mu_0)\n",
    "posterior = torch.distributions.MultivariateNormal(mu_n, precision_matrix=L_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marginal(dist: torch.distributions.Normal, i, j=None):\n",
    "    \n",
    "    if j is None:\n",
    "        mean = dist.mean[i]\n",
    "        var = dist.covariance_matrix[i, i]\n",
    "        return torch.distributions.Normal(mean, var.sqrt())\n",
    "    else:\n",
    "        mean = dist.mean[[i, j]]\n",
    "        v = dist.covariance_matrix\n",
    "        cov = torch.tensor([\n",
    "            [v[i, i], v[i, j]],\n",
    "            [v[j, i], v[j, j]],\n",
    "        ])\n",
    "        return torch.distributions.MultivariateNormal(mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "def to_matrix(samples):\n",
    "    return torch.stack(list(samples.values())).numpy()\n",
    "\n",
    "sample_data = pd.concat(\n",
    "    pd.DataFrame(to_matrix(torch.load(r.path / \"saved_samples.pt\")))\n",
    "    .rename_axis(index=\"sample\")\n",
    "    .assign(\n",
    "        sampler=r.config[\"inference\"][\"sampler\"][\"_target_\"],\n",
    "        batch_size=r.config[\"data\"][\"batch_size\"],\n",
    "    )\n",
    "    .set_index([\"sampler\", \"batch_size\"], append=True)\n",
    "    .reorder_levels([\"sampler\", \"batch_size\", \"sample\"])\n",
    "    for r in run.runs if \"sampler\" in r.config[\"inference\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.cubehelix_palette(start=2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(map(lambda x: sns.cubehelix_palette(rot=x), [0, -0.4, 2.8]))\n",
    "\n",
    "plot_cfg = {\n",
    "    ('src.inference.mcmc.samplers.HMC', 15): {\"color_palette\": \"Blues_r\"},\n",
    "    ('src.inference.mcmc.samplers.HMC', 5): {\"color_palette\": \"Greens_r\"},\n",
    "    ('src.inference.mcmc.samplers.SGHMC', 5): {\"color_palette\": \"Oranges_r\"}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_univariate(x, **kwargs):\n",
    "    i = x.name\n",
    "    marg = get_marginal(posterior, i)\n",
    "    xlims = min(x), max(x)\n",
    "    xx = torch.linspace(*xlims)\n",
    "    yy = marg.log_prob(xx).exp()\n",
    "    plt.plot(xx, yy, c=\"black\")\n",
    "\n",
    "def plot_bivariate(x, y, **kwargs):\n",
    "    i = x.name\n",
    "    j = y.name\n",
    "    marg = get_marginal(posterior, i, j)\n",
    "    xlims = min(x), max(x)\n",
    "    ylims = min(y), max(y)\n",
    "    xx = torch.linspace(*xlims, 400)\n",
    "    yy = torch.linspace(*ylims, 400)\n",
    "    XY = torch.stack(torch.meshgrid(xx, yy), dim=-1)\n",
    "    ZZ = marg.log_prob(XY).exp()\n",
    "    plt.contour(XY[..., 0], XY[..., 1], ZZ, colors=\"black\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = {}\n",
    "for key, data in sample_data.groupby(level=[0, 1]):\n",
    "    with sns.color_palette(plot_cfg[key][\"color_palette\"]):\n",
    "        plots[key] = sns.pairplot(\n",
    "            data,\n",
    "            kind=\"hist\",\n",
    "            diag_kws={\"stat\": \"density\"}\n",
    "        )\n",
    "        plots[key].map_diag(plot_univariate)\n",
    "        plots[key].map_offdiag(plot_bivariate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "j = 3\n",
    "joint_plots = {}\n",
    "for key, data in sample_data[[i, j]].groupby(level=[0, 1]):\n",
    "    with(sns.color_palette(plot_cfg[key][\"color_palette\"])):\n",
    "        x = data[i]\n",
    "        y = data[j]\n",
    "        joint_plots[key] = sns.jointplot(x=data[i], y=data[j], kind=\"hist\")\n",
    "        plt.sca(joint_plots[key].ax_joint)\n",
    "        plot_bivariate(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "n_samples = 10_000\n",
    "param_samples = posterior.sample((n_samples,))\n",
    "XX = torch.stack([torch.ones_like(xx), xx, xx**2, xx**3]).T\n",
    "predictions = XX @ param_samples.unsqueeze(-1)\n",
    "\n",
    "(\n",
    "    pd.DataFrame(predictions.squeeze().numpy(), columns=XX[:, 1].numpy())\n",
    "    .melt(\n",
    "        var_name=\"x\",\n",
    "        value_name=\"y\",\n",
    "    )\n",
    "    .groupby(\"x\")\n",
    "    .quantile([0.05, 0.5, 0.95])\n",
    "    .unstack()\n",
    "    .droplevel(0, axis=\"columns\")\n",
    "    .reset_index()\n",
    "    .melt(\n",
    "        id_vars=\"x\",\n",
    "        var_name=\"quantile\",\n",
    "    )\n",
    "    .pipe((sns.relplot, \"data\"), x=\"x\", y=\"value\", hue=\"quantile\", kind=\"line\")\n",
    ")\n",
    "plt.scatter(X[:,1], y)\n",
    "plt.plot(xx, eval_poly(xx, coeffs))\n",
    "plt.plot(xx, eval_poly(xx, sgd_inf.model.linear.weight.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0 = 0\n",
    "sigma_0 = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_data.dataset.tensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bayesian.priors import ScaleMixturePrior, NormalPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = ScaleMixturePrior(0, 0, 2, 0)\n",
    "xx = torch.linspace(-20, 20, 300)\n",
    "plt.plot(xx, prior.log_prob(xx).exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs_path = Path(\"../experiment_results/iris/2021-11-20/23-35-21\").resolve()\n",
    "runs = Experiment(\"iris\").latest_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sghmc = next(\n",
    "    run\n",
    "    for run in runs.runs if\n",
    "    run.config[\"inference\"][\"_target_\"] == \"src.inference.mcmc.MCMCInference\"\n",
    "    and run.config[\"inference\"][\"sampler\"][\"_target_\"]\n",
    "    == \"src.inference.mcmc.samplers.SGHMC\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_batched = next(\n",
    "    run\n",
    "    for run in runs.runs\n",
    "    if run.config[\"data\"][\"batch_size\"] != -1\n",
    "    and run.config[\"inference\"][\"_target_\"] == \"src.inference.mcmc.MCMCInference\"\n",
    "    and run.config[\"inference\"][\"sampler\"][\"_target_\"]\n",
    "    == \"src.inference.mcmc.samplers.HMC\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_full = next(\n",
    "    run\n",
    "    for run in runs.runs\n",
    "    if run.config[\"data\"][\"batch_size\"] == -1\n",
    "    and run.config[\"inference\"][\"_target_\"] == \"src.inference.mcmc.MCMCInference\"\n",
    "    and run.config[\"inference\"][\"sampler\"][\"_target_\"]\n",
    "    == \"src.inference.mcmc.samplers.HMC\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def get_samples(run):\n",
    "    samples = torch.load((run.path / \"saved_samples.pt\"))\n",
    "\n",
    "    def flatten_sample(sample):\n",
    "        a_1, a_2 = sample[\"linear.weight\"][:, 0].numpy()\n",
    "        b_1, b_2 = sample[\"linear.weight\"][:, 1].numpy()\n",
    "        c_1, c_2 = sample[\"linear.bias\"].numpy()\n",
    "\n",
    "        return {\n",
    "            \"a_1\": a_1,\n",
    "            \"a_2\": a_2,\n",
    "            \"b_1\": b_1,\n",
    "            \"b_2\": b_2,\n",
    "            \"c_1\": c_1,\n",
    "            \"c_2\": c_2,\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_records([flatten_sample(sample) for sample in samples.values()])\n",
    "\n",
    "hmc_full_data = get_samples(hmc_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_samples.loc[\"sghmc\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_samples = pd.concat(\n",
    "    [get_samples(hmc_full), get_samples(hmc_batched), get_samples(sghmc)],\n",
    "    keys=[\"full\", \"batched\", \"sghmc\"],\n",
    "    names=[\"algorithm\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    mcmc_samples.reset_index(level=\"algorithm\")\n",
    "    .reset_index(drop=True)\n",
    "    .pipe((sns.pairplot, \"data\"), hue=\"algorithm\", kind=\"kde\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sghmc.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(hmc_full_data, kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_full_data.columns = pd.MultiIndex.from_tuples([x.split(\"_\") for x in hmc_full_data.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.load_dataset(\"penguins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(hmc_full_data.melt(col_level=1), hue=\"variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.relplot(data=iris_data, x=\"Component 1\", y=\"Component 2\", hue=\"Species\", col=\"Split\")\n",
    "for ax in fg.axes.flatten():\n",
    "    plt.sca(ax)\n",
    "    for between in [(1, 2), (0, 1)]:\n",
    "        slope, intercept = get_decision_boundary(sgd_inference.model, between)\n",
    "        plt.axline((0, intercept), slope=slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use toy model, but with categorial likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_inference = VariationalInference(\n",
    "    model=PolynomialClassifier(4, 3, bias=False),\n",
    "    lr=1e-3,\n",
    "    n_particles=10,\n",
    ")\n",
    "trainer = Trainer()\n",
    "trainer.fit(\n",
    "    model=vi_inference,\n",
    "    train_dataloaders=DataLoader(train_data, batch_size=8, shuffle=True),\n",
    "    val_dataloaders=DataLoader(test_data, batch_size=8),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_inference = MCMCInference(\n",
    "    model=PolynomialClassifier(4, 3, bias=False),\n",
    "    burn_in=50\n",
    ")\n",
    "trainer = Trainer()\n",
    "trainer.fit(\n",
    "    model=mcmc_inference,\n",
    "    train_dataloaders=DataLoader(train_data, batch_size=8, shuffle=True),\n",
    "    val_dataloaders=DataLoader(test_data, batch_size=8),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.DataFrame(torch.stack(list(mcmc_inference.sample_container.samples.values())).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IrisModel(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Hamiltonian(step_size=0.04)\n",
    "inference = MonteCarloInference(sampler=sampler)\n",
    "inference.fit(model, train_data, burn_in=2000, n_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.DataFrame({f\"$c_{i}$\" : c for i, c in enumerate(inference.samples_.T)})\n",
    "plot_data = sample_df.reset_index().melt(id_vars=\"index\")\n",
    "fig = plt.figure()\n",
    "grid_spec = fig.add_gridspec(2, 1, height_ratios=(2, 7))\n",
    "\n",
    "ax_line = fig.add_subplot(grid_spec[1, 0])\n",
    "ax_marg = fig.add_subplot(grid_spec[0, 0], sharex=ax_line)\n",
    "\n",
    "sns.lineplot(x = \"value\", y=\"index\", hue=\"variable\", ax=ax_line, data=plot_data, sort=False, legend=False)\n",
    "sns.kdeplot(x = \"value\", hue=\"variable\", data=plot_data, legend=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_samples = inference.predictive(x_test)\n",
    "y_pred = torch.tensor([v.bincount(minlength=3).argmax() for v in y_pred_samples.argmax(-1).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certainty = (y_pred == y_pred_samples.argmax(-1)).sum(0) / 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = pca.transform(x_test).T\n",
    "# sns.scatterplot(x=u, y=v, hue=y_pred)\n",
    "sns.scatterplot(x=u, y=v, hue=certainty)\n",
    "plt.figure()\n",
    "sns.scatterplot(x=u, y=v, hue=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d767b8386092d7cf7d2b9cae3bbc1311fb6c0ac52cead8f221dab1753f4d4fb8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
