{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch.nn import Linear, Sequential, ReLU\n",
    "from src.bayesian.core import *\n",
    "from src.bayesian.core import _IMPLEMENTED_BAYESIAN_MODULES\n",
    "from src.inference.vi import VariationalInference\n",
    "from src.models.base import Model, ClassifierMixin\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Model, Sequential, ClassifierMixin):\n",
    "    pass\n",
    "        \n",
    "net = Net(Linear(4, 10), ReLU(), Linear(10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = torch.tensor(iris[\"data\"], dtype=torch.float32)\n",
    "y = torch.tensor(iris[\"target\"])\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = from_default_prior(ScaleMixturePrior())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianConversionConfig(modules_to_replace={<class 'torch.nn.modules.linear.Linear'>: BayesianModuleConfig(module=<class 'src.bayesian.modules.BayesianLinear'>, priors={'weight': ScaleMixturePrior(), 'bias': ScaleMixturePrior()})})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = VariationalInference(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | model         | Net        | 166   \n",
      "1 | train_metrics | ModuleDict | 0     \n",
      "2 | val_metrics   | ModuleDict | 0     \n",
      "---------------------------------------------\n",
      "166       Trainable params\n",
      "0         Non-trainable params\n",
      "166       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soren/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:376: UserWarning: Your val_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/Users/soren/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VariationalInference' object has no attribute 'w_samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b2/59jjzwlx2m78ct45dplq50jh0000gn/T/ipykernel_67242/272817159.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trainer.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minference\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_dataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         dl_outputs = self.epoch_loop.run(\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mdataloader_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_dataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         )\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, dataloader_iter, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \"\"\"\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/src/inference/vi.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/Speciale/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1131\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VariationalInference' object has no attribute 'w_samples'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=500)\n",
    "trainer.fit(\n",
    "    inference,\n",
    "    train_dataloaders=torch.utils.data.DataLoader(train_dataset, batch_size=25, shuffle=True),\n",
    "    val_dataloaders=torch.utils.data.DataLoader(test_dataset, batch_size=25, shuffle=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.4588, -4.4540, -4.4615, -4.4584],\n",
       "        [-4.4642, -4.4572, -4.4567, -4.4530],\n",
       "        [-4.4612, -4.4575, -4.4579, -4.4553],\n",
       "        [-4.4618, -4.4559, -4.4582, -4.4519],\n",
       "        [-4.4645, -4.4584, -4.4611, -4.4510],\n",
       "        [-4.4676, -4.4588, -4.4592, -4.4523],\n",
       "        [-4.4623, -4.4556, -4.4582, -4.4544],\n",
       "        [-4.4641, -4.4575, -4.4573, -4.4544],\n",
       "        [-4.4621, -4.4561, -4.4596, -4.4553],\n",
       "        [-4.4648, -4.4575, -4.4589, -4.4528]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net[0].variational_parameters[\"weight\"].rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b2/59jjzwlx2m78ct45dplq50jh0000gn/T/ipykernel_30704/2813511426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., 2., 3.], [20., 40, 60.]])\n",
    "model = nn.Sequential\n",
    "\n",
    "a = BayesianLinear.from_freq_module(nn.Linear(3, 5))\n",
    "b = VariationalModule(a)\n",
    "\n",
    "x_expanded = x.unsqueeze(0).expand((n_particles, *x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23.4538, 38.5276, 65.9396],\n",
       "        [22.1915, 40.8026, 65.3294],\n",
       "        [17.1115, 41.4849, 66.6112],\n",
       "        [23.3285, 40.7437, 63.9023],\n",
       "        [24.6270, 43.1445, 66.6718]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = b(x_expanded, n_particles=n_particles)\n",
    "loglik_standin = out.sum((1, 2))\n",
    "elbo = (loglik_standin + b.log_prior() + b.log_v_post()).mean()\n",
    "b.zero_grad()\n",
    "elbo.backward()\n",
    "b.variational_parameters[\"weight\"].mu.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-32.1241, -20.8085,  55.0730],\n",
       "        [-36.8658,  -0.7628,  58.0859],\n",
       "        [-34.9798,  24.1958,  64.2660],\n",
       "        [-17.7285,  -7.2025,  42.2222],\n",
       "        [-23.5499,   5.1829,  60.1604]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.update_gradients_()\n",
    "b.variational_parameters[\"weight\"].mu.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VariationalModule(\n",
       "  (bayesian_module): BayesianLinear(\n",
       "    (priors): ModuleDict(\n",
       "      (weight): ScaleMixturePrior()\n",
       "      (bias): ScaleMixturePrior()\n",
       "    )\n",
       "  )\n",
       "  (variational_parameters): ModuleDict(\n",
       "    (weight): Module()\n",
       "    (bias): Module()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.cifar import CIFARDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = CIFARDataModule()\n",
    "dm.setup()\n",
    "train_loader = dm.train_dataloader()\n",
    "X, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeHaveBatchNorm2dAtHome(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, scale, shift):\n",
    "        super().__init__()\n",
    "        self.register_parameter(\"scale\", torch.nn.Parameter(scale.view(1, -1, 1, 1)))\n",
    "        self.register_parameter(\"shift\", torch.nn.Parameter(shift.view(1, -1, 1, 1)))\n",
    "    def forward(self, x):\n",
    "        return self.scale * x + self.shift\n",
    "\n",
    "    @classmethod\n",
    "    def from_batchnorm2d(cls, norm):\n",
    "        a = 1/torch.sqrt(norm.running_var + norm.eps) * norm.weight.detach()\n",
    "        b = -norm.running_mean*a + norm.bias.detach()\n",
    "        return cls(a, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenorm = WeHaveBatchNorm2dAtHome.from_batchnorm2d(model.features.norm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.9379e-02,  7.1383e-02,  6.8835e-02,  ...,  7.3523e-02,\n",
       "            7.4663e-02,  8.0896e-02],\n",
       "          [ 8.7760e-02,  8.4119e-02,  8.3099e-02,  ...,  8.5306e-02,\n",
       "            8.4128e-02,  8.7573e-02],\n",
       "          [ 9.0997e-02,  8.9074e-02,  8.9966e-02,  ...,  9.3295e-02,\n",
       "            8.9264e-02,  8.9927e-02],\n",
       "          ...,\n",
       "          [ 1.0251e-01,  1.1618e-01,  1.2741e-01,  ...,  6.0238e-02,\n",
       "            6.1609e-02,  7.0405e-02],\n",
       "          [ 1.1096e-01,  1.2191e-01,  1.3123e-01,  ...,  7.8494e-02,\n",
       "            8.6942e-02,  9.2082e-02],\n",
       "          [ 1.0686e-01,  9.8975e-02,  8.4568e-02,  ...,  1.2511e-01,\n",
       "            1.2446e-01,  1.1611e-01]],\n",
       "\n",
       "         [[ 3.5888e-02,  3.7583e-02,  3.7414e-02,  ...,  3.9420e-02,\n",
       "            3.9037e-02,  4.1402e-02],\n",
       "          [ 3.9997e-02,  3.8029e-02,  3.8449e-02,  ...,  3.8528e-02,\n",
       "            3.8738e-02,  3.8797e-02],\n",
       "          [ 3.9698e-02,  3.8177e-02,  3.8644e-02,  ...,  4.1006e-02,\n",
       "            3.8224e-02,  3.8121e-02],\n",
       "          ...,\n",
       "          [ 2.3574e-02,  3.4700e-02,  7.5574e-02,  ...,  2.0319e-02,\n",
       "            4.0508e-02,  3.4965e-02],\n",
       "          [ 7.7698e-02,  8.3264e-02,  5.3708e-02,  ...,  4.0502e-02,\n",
       "            3.8696e-02,  3.7520e-02],\n",
       "          [ 3.0404e-02,  2.6509e-02,  2.7093e-02,  ...,  3.6524e-02,\n",
       "            3.7088e-02,  4.9994e-02]],\n",
       "\n",
       "         [[ 4.0891e-02,  3.5189e-02,  3.4012e-02,  ...,  3.3638e-02,\n",
       "            3.2703e-02,  6.4614e-03],\n",
       "          [ 3.9158e-02,  3.5539e-02,  3.4607e-02,  ...,  3.4854e-02,\n",
       "            3.3693e-02,  1.6700e-03],\n",
       "          [ 3.9493e-02,  3.6196e-02,  3.5006e-02,  ...,  3.4312e-02,\n",
       "            3.3946e-02, -3.4805e-03],\n",
       "          ...,\n",
       "          [ 5.1709e-02,  3.7210e-02,  2.6495e-02,  ...,  3.2726e-02,\n",
       "            3.2536e-02, -1.4863e-02],\n",
       "          [ 3.9978e-02,  3.4631e-02,  3.6656e-02,  ...,  3.4328e-02,\n",
       "            3.3352e-02, -1.8444e-02],\n",
       "          [ 2.8548e-02,  3.4555e-02,  3.3958e-02,  ...,  3.3722e-02,\n",
       "            3.2224e-02,  9.2310e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.5609e-02,  1.9481e-02,  2.2128e-02,  ...,  2.1607e-02,\n",
       "            2.2869e-02,  2.0490e-02],\n",
       "          [ 5.7939e-02,  2.7059e-02,  2.8362e-02,  ...,  2.3847e-02,\n",
       "            2.6112e-02,  2.5059e-02],\n",
       "          [ 6.0947e-02,  2.5871e-02,  2.6840e-02,  ...,  3.2286e-02,\n",
       "            2.4442e-02,  2.4459e-02],\n",
       "          ...,\n",
       "          [ 8.2190e-02,  1.5245e-02,  3.6233e-02,  ...,  3.1245e-02,\n",
       "            2.4123e-02,  1.6402e-02],\n",
       "          [ 7.0674e-02, -3.0480e-03,  3.5105e-03,  ...,  2.5777e-02,\n",
       "            3.1268e-02,  2.7707e-02],\n",
       "          [ 6.7160e-02,  1.7566e-02, -4.3820e-03,  ...,  4.1886e-02,\n",
       "            4.2271e-02,  4.4348e-02]],\n",
       "\n",
       "         [[ 2.6397e-02,  3.6549e-02,  3.8616e-02,  ...,  4.1038e-02,\n",
       "            4.0269e-02,  4.5602e-02],\n",
       "          [ 2.9745e-02,  3.7350e-02,  3.8869e-02,  ...,  4.1130e-02,\n",
       "            4.0984e-02,  4.2907e-02],\n",
       "          [ 3.0774e-02,  3.8832e-02,  3.9453e-02,  ...,  3.1426e-02,\n",
       "            4.1065e-02,  4.4159e-02],\n",
       "          ...,\n",
       "          [ 1.7222e-02,  1.8524e-02, -1.0051e-02,  ...,  4.4256e-02,\n",
       "            3.6202e-02,  4.6458e-02],\n",
       "          [ 3.7121e-02,  6.0694e-02,  6.8508e-02,  ...,  3.6621e-02,\n",
       "            3.4304e-02,  4.0221e-02],\n",
       "          [ 1.7055e-02,  3.0601e-02,  5.9315e-02,  ...,  2.7397e-03,\n",
       "            4.4241e-03,  1.3524e-02]],\n",
       "\n",
       "         [[ 1.9805e-01,  2.0243e-01,  2.0582e-01,  ...,  2.1381e-01,\n",
       "            2.1436e-01,  1.9740e-01],\n",
       "          [ 2.0108e-01,  2.0592e-01,  2.1160e-01,  ...,  2.2325e-01,\n",
       "            2.2592e-01,  2.0390e-01],\n",
       "          [ 1.9316e-01,  1.9642e-01,  2.0154e-01,  ...,  2.0799e-01,\n",
       "            2.1801e-01,  1.9939e-01],\n",
       "          ...,\n",
       "          [ 1.7332e-01,  1.6895e-01,  1.7905e-01,  ...,  1.4535e-01,\n",
       "            1.5263e-01,  1.6596e-01],\n",
       "          [ 1.7833e-01,  1.7061e-01,  1.7305e-01,  ...,  1.3851e-01,\n",
       "            1.4328e-01,  1.6419e-01],\n",
       "          [ 1.8649e-01,  1.7950e-01,  1.8215e-01,  ...,  1.6612e-01,\n",
       "            1.6825e-01,  1.7788e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.7624e-02,  8.2542e-02,  7.9438e-02,  ...,  9.5423e-02,\n",
       "            1.0033e-01,  1.0132e-01],\n",
       "          [ 9.3371e-02,  9.2600e-02,  9.2641e-02,  ...,  1.0486e-01,\n",
       "            1.0426e-01,  1.0181e-01],\n",
       "          [ 9.7207e-02,  9.8762e-02,  1.0003e-01,  ...,  1.0576e-01,\n",
       "            1.0447e-01,  1.0117e-01],\n",
       "          ...,\n",
       "          [ 9.7192e-02,  9.7736e-02,  9.5234e-02,  ...,  9.1437e-02,\n",
       "            9.2747e-02,  9.4099e-02],\n",
       "          [ 9.6045e-02,  9.6232e-02,  9.6151e-02,  ...,  9.5724e-02,\n",
       "            9.6858e-02,  9.6899e-02],\n",
       "          [ 8.0088e-02,  7.2684e-02,  7.0601e-02,  ...,  7.2372e-02,\n",
       "            7.1850e-02,  7.7967e-02]],\n",
       "\n",
       "         [[ 3.6276e-02,  3.6905e-02,  3.8085e-02,  ...,  5.0296e-02,\n",
       "            4.6908e-02,  3.8760e-02],\n",
       "          [ 4.0092e-02,  3.9504e-02,  4.0124e-02,  ...,  3.9478e-02,\n",
       "            4.2820e-02,  4.7285e-02],\n",
       "          [ 4.0125e-02,  3.9471e-02,  4.0062e-02,  ...,  4.3425e-02,\n",
       "            3.8416e-02,  4.2272e-02],\n",
       "          ...,\n",
       "          [ 4.0821e-02,  4.3731e-02,  4.4480e-02,  ...,  4.0284e-02,\n",
       "            4.1414e-02,  4.2058e-02],\n",
       "          [ 4.1752e-02,  4.1215e-02,  4.1469e-02,  ...,  4.0244e-02,\n",
       "            4.0107e-02,  4.1170e-02],\n",
       "          [ 5.5565e-02,  4.5031e-02,  4.2993e-02,  ...,  4.7297e-02,\n",
       "            4.6143e-02,  3.3506e-02]],\n",
       "\n",
       "         [[ 3.6707e-02,  3.3925e-02,  3.3698e-02,  ...,  3.3865e-02,\n",
       "            4.0065e-02,  4.4239e-02],\n",
       "          [ 3.6574e-02,  3.4528e-02,  3.4871e-02,  ...,  2.5268e-02,\n",
       "            3.1242e-02,  4.2160e-02],\n",
       "          [ 3.5852e-02,  3.4910e-02,  3.5199e-02,  ...,  1.5490e-02,\n",
       "            3.5204e-02,  5.0683e-02],\n",
       "          ...,\n",
       "          [ 3.0006e-02,  3.4209e-02,  3.2439e-02,  ...,  3.3220e-02,\n",
       "            3.3835e-02,  8.0542e-02],\n",
       "          [ 3.0725e-02,  3.2219e-02,  3.1640e-02,  ...,  3.3450e-02,\n",
       "            3.2968e-02,  8.3995e-02],\n",
       "          [ 3.3958e-02,  3.3466e-02,  3.3612e-02,  ...,  3.3810e-02,\n",
       "            3.3862e-02,  6.7460e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7835e-02,  3.0103e-02,  2.8596e-02,  ...,  2.2575e-02,\n",
       "            2.6052e-02,  3.6716e-02],\n",
       "          [ 4.1377e-02,  3.4733e-02,  3.4204e-02,  ...,  2.7699e-02,\n",
       "            2.2869e-02,  3.9469e-02],\n",
       "          [ 4.0878e-02,  3.4485e-02,  3.3719e-02,  ...,  3.2549e-02,\n",
       "            1.9326e-02,  4.1262e-02],\n",
       "          ...,\n",
       "          [-5.1181e-03,  3.2970e-02,  3.8059e-02,  ...,  3.2194e-02,\n",
       "            3.2806e-02,  3.2746e-02],\n",
       "          [-5.1646e-03,  3.3940e-02,  3.4525e-02,  ...,  3.2255e-02,\n",
       "            3.2455e-02,  3.2581e-02],\n",
       "          [-6.8591e-03,  1.7512e-02,  2.1620e-02,  ...,  2.0895e-02,\n",
       "            2.1460e-02,  1.8358e-02]],\n",
       "\n",
       "         [[ 3.0764e-02,  3.2779e-02,  3.3892e-02,  ...,  3.8131e-02,\n",
       "            3.8351e-02,  3.5287e-02],\n",
       "          [ 3.4116e-02,  3.5074e-02,  3.4975e-02,  ...,  3.8802e-02,\n",
       "            3.8421e-02,  3.0851e-02],\n",
       "          [ 3.3908e-02,  3.4582e-02,  3.4812e-02,  ...,  3.6358e-02,\n",
       "            3.9600e-02,  3.1853e-02],\n",
       "          ...,\n",
       "          [ 4.9174e-02,  4.1691e-02,  3.8520e-02,  ...,  4.2401e-02,\n",
       "            4.0820e-02,  3.5682e-02],\n",
       "          [ 4.9204e-02,  4.1335e-02,  3.9710e-02,  ...,  4.0304e-02,\n",
       "            4.1013e-02,  3.5896e-02],\n",
       "          [ 6.7940e-02,  7.2471e-02,  7.0403e-02,  ...,  6.8981e-02,\n",
       "            6.9409e-02,  6.2103e-02]],\n",
       "\n",
       "         [[ 2.1453e-01,  2.2572e-01,  2.2853e-01,  ...,  2.2061e-01,\n",
       "            2.1507e-01,  1.9942e-01],\n",
       "          [ 2.2780e-01,  2.4375e-01,  2.4637e-01,  ...,  2.3501e-01,\n",
       "            2.2939e-01,  2.0753e-01],\n",
       "          [ 2.2811e-01,  2.4349e-01,  2.4426e-01,  ...,  2.3119e-01,\n",
       "            2.2639e-01,  2.0480e-01],\n",
       "          ...,\n",
       "          [ 1.8580e-01,  2.0105e-01,  2.0134e-01,  ...,  1.9593e-01,\n",
       "            1.9453e-01,  1.9072e-01],\n",
       "          [ 1.9138e-01,  2.0128e-01,  1.9949e-01,  ...,  1.9695e-01,\n",
       "            1.9637e-01,  1.9133e-01],\n",
       "          [ 1.8654e-01,  1.9221e-01,  1.9084e-01,  ...,  1.8803e-01,\n",
       "            1.8800e-01,  1.8495e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2323e-01,  1.3325e-01,  1.2870e-01,  ...,  1.4197e-01,\n",
       "            1.4204e-01,  1.2914e-01],\n",
       "          [ 1.0423e-01,  1.0662e-01,  1.0333e-01,  ...,  1.0961e-01,\n",
       "            1.0970e-01,  1.0572e-01],\n",
       "          [ 9.5728e-02,  9.7120e-02,  9.6196e-02,  ...,  9.5948e-02,\n",
       "            9.5886e-02,  9.5834e-02],\n",
       "          ...,\n",
       "          [ 9.5628e-02,  9.5518e-02,  9.4301e-02,  ...,  8.5187e-02,\n",
       "            9.1830e-02,  9.5851e-02],\n",
       "          [ 9.5786e-02,  9.5249e-02,  8.9160e-02,  ...,  7.8573e-02,\n",
       "            8.5487e-02,  9.3673e-02],\n",
       "          [ 7.4201e-02,  6.3107e-02,  5.8806e-02,  ...,  6.4864e-02,\n",
       "            5.9909e-02,  6.8253e-02]],\n",
       "\n",
       "         [[ 5.1542e-02,  4.3375e-02,  3.6287e-02,  ...,  4.5219e-02,\n",
       "            4.5234e-02,  3.6799e-02],\n",
       "          [ 4.1138e-02,  4.1825e-02,  4.1138e-02,  ...,  4.2699e-02,\n",
       "            4.2730e-02,  4.3129e-02],\n",
       "          [ 4.1574e-02,  4.0758e-02,  4.1474e-02,  ...,  4.2479e-02,\n",
       "            4.2436e-02,  4.2155e-02],\n",
       "          ...,\n",
       "          [ 4.1536e-02,  4.2372e-02,  4.2062e-02,  ...,  4.0458e-02,\n",
       "            4.0929e-02,  4.2104e-02],\n",
       "          [ 4.1585e-02,  4.2787e-02,  4.6014e-02,  ...,  3.7614e-02,\n",
       "            3.9300e-02,  4.1231e-02],\n",
       "          [ 6.1373e-02,  4.6552e-02,  2.3557e-02,  ...,  4.6744e-02,\n",
       "            5.3106e-02,  3.0447e-02]],\n",
       "\n",
       "         [[ 2.4397e-02,  2.2546e-02,  2.6321e-02,  ...,  3.4436e-02,\n",
       "            3.4409e-02,  9.8772e-02],\n",
       "          [ 2.7738e-02,  2.0347e-02,  2.4556e-02,  ...,  3.3322e-02,\n",
       "            3.3363e-02,  1.0188e-01],\n",
       "          [ 2.7553e-02,  1.6541e-02,  3.8574e-02,  ...,  3.3392e-02,\n",
       "            3.3493e-02,  1.0265e-01],\n",
       "          ...,\n",
       "          [ 2.7778e-02,  3.2725e-02,  2.9111e-02,  ...,  3.5186e-02,\n",
       "            3.3349e-02,  1.0350e-01],\n",
       "          [ 2.8004e-02,  3.1700e-02,  3.4535e-02,  ...,  3.4219e-02,\n",
       "            3.2417e-02,  1.0321e-01],\n",
       "          [ 3.2745e-02,  3.0935e-02,  3.9674e-02,  ...,  2.6497e-02,\n",
       "            3.3016e-02,  7.8129e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1083e-04,  5.1366e-02,  6.0980e-02,  ...,  4.6848e-02,\n",
       "            4.7185e-02,  5.7968e-02],\n",
       "          [-2.0324e-02,  3.1863e-02,  5.2149e-02,  ...,  3.2357e-02,\n",
       "            3.2851e-02,  3.7226e-02],\n",
       "          [-1.8904e-02,  3.0553e-02,  5.1085e-02,  ...,  3.3479e-02,\n",
       "            3.3966e-02,  3.3901e-02],\n",
       "          ...,\n",
       "          [-1.8463e-02,  3.3053e-02,  3.3876e-02,  ...,  1.5883e-02,\n",
       "            3.2845e-02,  3.3697e-02],\n",
       "          [-1.8507e-02,  3.3238e-02,  3.5618e-02,  ...,  2.9999e-03,\n",
       "            1.5597e-02,  3.5242e-02],\n",
       "          [-1.9339e-02,  1.0329e-02,  2.0929e-02,  ...,  1.0654e-02,\n",
       "           -8.1651e-03,  1.0587e-02]],\n",
       "\n",
       "         [[ 6.3560e-02,  4.1949e-02,  3.1727e-02,  ...,  4.2803e-02,\n",
       "            4.2712e-02,  2.4193e-02],\n",
       "          [ 5.6074e-02,  4.3196e-02,  3.2979e-02,  ...,  4.3580e-02,\n",
       "            4.3386e-02,  3.5391e-02],\n",
       "          [ 5.3634e-02,  4.2369e-02,  3.1340e-02,  ...,  4.1970e-02,\n",
       "            4.1950e-02,  3.5308e-02],\n",
       "          ...,\n",
       "          [ 5.3374e-02,  4.3936e-02,  4.1325e-02,  ...,  5.6300e-02,\n",
       "            4.4077e-02,  3.5053e-02],\n",
       "          [ 5.3521e-02,  4.3945e-02,  4.2847e-02,  ...,  6.4351e-02,\n",
       "            5.5279e-02,  3.5325e-02],\n",
       "          [ 7.8510e-02,  8.4913e-02,  7.0351e-02,  ...,  6.7074e-02,\n",
       "            8.7695e-02,  7.5446e-02]],\n",
       "\n",
       "         [[ 1.8108e-01,  1.8266e-01,  1.7457e-01,  ...,  1.8586e-01,\n",
       "            1.8596e-01,  1.8506e-01],\n",
       "          [ 1.8308e-01,  1.8560e-01,  1.7532e-01,  ...,  1.9247e-01,\n",
       "            1.9222e-01,  1.8807e-01],\n",
       "          [ 1.8143e-01,  1.8469e-01,  1.7386e-01,  ...,  1.8966e-01,\n",
       "            1.8980e-01,  1.8715e-01],\n",
       "          ...,\n",
       "          [ 1.8120e-01,  1.9016e-01,  1.8381e-01,  ...,  1.8392e-01,\n",
       "            1.9014e-01,  1.8889e-01],\n",
       "          [ 1.8101e-01,  1.8979e-01,  1.7826e-01,  ...,  1.7574e-01,\n",
       "            1.8405e-01,  1.8844e-01],\n",
       "          [ 1.7804e-01,  1.8145e-01,  1.7410e-01,  ...,  1.7505e-01,\n",
       "            1.7681e-01,  1.8159e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.0497e-01,  1.0762e-01,  1.0476e-01,  ...,  8.3921e-02,\n",
       "            7.9428e-02,  8.1750e-02],\n",
       "          [ 9.5414e-02,  9.8145e-02,  1.0008e-01,  ...,  1.0191e-01,\n",
       "            9.9782e-02,  9.6790e-02],\n",
       "          [ 9.5868e-02,  9.9440e-02,  1.0572e-01,  ...,  1.2064e-01,\n",
       "            1.2510e-01,  1.1828e-01],\n",
       "          ...,\n",
       "          [ 9.1075e-02,  9.0721e-02,  8.8657e-02,  ...,  9.1316e-02,\n",
       "            8.0351e-02,  7.6667e-02],\n",
       "          [ 9.2281e-02,  9.2438e-02,  9.6357e-02,  ...,  1.0630e-01,\n",
       "            1.0070e-01,  9.5843e-02],\n",
       "          [ 9.0960e-02,  8.9884e-02,  9.2366e-02,  ...,  8.2452e-02,\n",
       "            9.1959e-02,  9.7458e-02]],\n",
       "\n",
       "         [[ 4.8679e-02,  4.9737e-02,  4.7969e-02,  ..., -2.3688e-02,\n",
       "           -3.5289e-04,  4.0397e-02],\n",
       "          [ 3.2888e-02,  3.8085e-02,  4.3136e-02,  ...,  1.1077e-01,\n",
       "            7.3023e-02,  2.2158e-02],\n",
       "          [ 4.4449e-02,  3.5846e-02,  3.6840e-02,  ...,  1.3280e-02,\n",
       "            1.2958e-02,  6.5905e-02],\n",
       "          ...,\n",
       "          [ 3.2522e-02,  3.3046e-02,  3.9350e-02,  ...,  3.1969e-02,\n",
       "            1.5012e-02,  2.5395e-02],\n",
       "          [ 4.1282e-02,  4.0553e-02,  2.6576e-02,  ...,  7.0644e-02,\n",
       "            6.1112e-02,  4.4396e-02],\n",
       "          [ 4.2792e-02,  4.8131e-02,  5.5781e-02,  ...,  2.9584e-02,\n",
       "            4.0535e-02,  4.6778e-02]],\n",
       "\n",
       "         [[ 2.0993e-02,  1.3918e-02,  2.5660e-02,  ...,  3.7697e-02,\n",
       "            3.0451e-02,  2.4429e-03],\n",
       "          [ 2.9528e-02,  1.5854e-02,  3.4770e-02,  ...,  2.6196e-02,\n",
       "            2.8219e-02,  2.8556e-02],\n",
       "          [ 2.2703e-02, -7.4140e-03,  3.8855e-02,  ...,  3.8928e-02,\n",
       "            3.9727e-02,  7.6299e-02],\n",
       "          ...,\n",
       "          [ 3.0669e-02,  8.7646e-03,  2.9615e-02,  ...,  2.8922e-02,\n",
       "            3.9075e-02,  9.0730e-02],\n",
       "          [ 4.0549e-02,  1.5617e-02,  4.4564e-02,  ...,  3.4502e-02,\n",
       "            5.5571e-02,  6.8298e-02],\n",
       "          [ 3.7614e-02,  2.9805e-02,  4.1324e-02,  ...,  3.6774e-02,\n",
       "            3.2230e-02,  5.0090e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7417e-02,  4.3935e-02,  4.9082e-02,  ...,  3.2007e-02,\n",
       "            4.1926e-02,  1.9582e-02],\n",
       "          [ 1.0457e-02,  3.2051e-02,  3.7928e-02,  ...,  4.9855e-02,\n",
       "            5.2075e-02,  3.4797e-02],\n",
       "          [ 1.3753e-02,  4.1794e-02,  2.6677e-02,  ...,  6.0804e-02,\n",
       "            5.8986e-02,  4.4382e-02],\n",
       "          ...,\n",
       "          [ 9.3363e-03,  3.6840e-02,  3.2284e-02,  ...,  8.6587e-02,\n",
       "            7.2118e-03, -1.8179e-02],\n",
       "          [ 1.4987e-02,  4.2500e-02,  3.0090e-02,  ...,  6.9538e-02,\n",
       "            7.4765e-02,  1.8142e-02],\n",
       "          [ 1.5193e-02,  3.2221e-02,  2.8839e-02,  ...,  2.3700e-02,\n",
       "            3.5142e-02,  3.5073e-02]],\n",
       "\n",
       "         [[ 5.1483e-02,  3.8203e-02,  2.5891e-02,  ...,  5.5685e-02,\n",
       "            4.1716e-02,  4.8451e-02],\n",
       "          [ 4.4509e-02,  4.2937e-02,  3.5957e-02,  ..., -5.1938e-04,\n",
       "            1.0948e-02,  2.5344e-02],\n",
       "          [ 3.6336e-02,  3.4934e-02,  3.6942e-02,  ...,  2.5926e-02,\n",
       "            2.4137e-02,  1.8227e-02],\n",
       "          ...,\n",
       "          [ 4.6884e-02,  4.5537e-02,  4.3471e-02,  ..., -1.9776e-02,\n",
       "            5.1757e-02,  8.3064e-02],\n",
       "          [ 3.8097e-02,  3.2115e-02,  3.2818e-02,  ...,  3.8259e-02,\n",
       "           -1.3062e-02,  1.1295e-02],\n",
       "          [ 5.1913e-02,  5.2517e-02,  5.0543e-02,  ...,  6.0596e-02,\n",
       "            7.0522e-02,  5.1026e-02]],\n",
       "\n",
       "         [[ 1.6948e-01,  1.6367e-01,  1.5658e-01,  ...,  1.1846e-01,\n",
       "            7.8074e-02,  9.2194e-02],\n",
       "          [ 1.7870e-01,  1.7481e-01,  1.7459e-01,  ...,  8.9406e-02,\n",
       "            4.4520e-02,  6.8520e-02],\n",
       "          [ 1.7803e-01,  1.7489e-01,  1.8249e-01,  ...,  1.1699e-01,\n",
       "            8.9652e-02,  1.2355e-01],\n",
       "          ...,\n",
       "          [ 1.4000e-01,  1.2691e-01,  1.2495e-01,  ...,  1.2969e-01,\n",
       "            1.3061e-01,  1.5652e-01],\n",
       "          [ 1.1107e-01,  1.0111e-01,  1.1586e-01,  ...,  1.3011e-01,\n",
       "            1.1355e-01,  1.3836e-01],\n",
       "          [ 1.2502e-01,  1.1937e-01,  1.3611e-01,  ...,  1.2731e-01,\n",
       "            1.0550e-01,  1.3375e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.2004e-02,  7.4867e-02,  7.1938e-02,  ...,  6.4188e-02,\n",
       "            6.3512e-02,  7.2122e-02],\n",
       "          [ 8.9886e-02,  8.7099e-02,  8.6097e-02,  ...,  8.3448e-02,\n",
       "            8.3195e-02,  8.6466e-02],\n",
       "          [ 9.3581e-02,  9.2811e-02,  9.2516e-02,  ...,  9.5813e-02,\n",
       "            9.5437e-02,  9.3365e-02],\n",
       "          ...,\n",
       "          [ 9.5929e-02,  9.5631e-02,  9.5993e-02,  ...,  9.7299e-02,\n",
       "            9.8021e-02,  9.7424e-02],\n",
       "          [ 9.4829e-02,  9.5381e-02,  9.6793e-02,  ...,  9.7352e-02,\n",
       "            9.8347e-02,  9.8188e-02],\n",
       "          [ 8.9795e-02,  8.7460e-02,  8.6998e-02,  ...,  8.9439e-02,\n",
       "            9.0376e-02,  9.2653e-02]],\n",
       "\n",
       "         [[ 3.5137e-02,  3.6609e-02,  3.7269e-02,  ...,  3.6238e-02,\n",
       "            3.5835e-02,  4.1195e-02],\n",
       "          [ 4.0169e-02,  3.8675e-02,  3.8635e-02,  ...,  3.7177e-02,\n",
       "            3.7602e-02,  3.7684e-02],\n",
       "          [ 3.9525e-02,  3.8460e-02,  3.8589e-02,  ...,  3.7875e-02,\n",
       "            4.0136e-02,  3.8567e-02],\n",
       "          ...,\n",
       "          [ 4.1619e-02,  4.3727e-02,  4.1327e-02,  ...,  3.7759e-02,\n",
       "            3.6720e-02,  3.4697e-02],\n",
       "          [ 4.1893e-02,  3.8631e-02,  3.9829e-02,  ...,  4.6376e-02,\n",
       "            4.6207e-02,  4.4399e-02],\n",
       "          [ 4.2718e-02,  4.6676e-02,  4.1951e-02,  ...,  3.9454e-02,\n",
       "            4.3820e-02,  3.8362e-02]],\n",
       "\n",
       "         [[ 3.9285e-02,  3.4702e-02,  3.4015e-02,  ...,  3.3875e-02,\n",
       "            3.3623e-02, -1.0962e-02],\n",
       "          [ 3.8195e-02,  3.5007e-02,  3.4975e-02,  ...,  3.4494e-02,\n",
       "            3.4671e-02, -1.4825e-02],\n",
       "          [ 3.8410e-02,  3.5251e-02,  3.5145e-02,  ...,  2.9469e-02,\n",
       "            3.4970e-02, -1.7519e-02],\n",
       "          ...,\n",
       "          [ 3.4015e-02,  3.5968e-02,  3.7041e-02,  ...,  3.2040e-02,\n",
       "            3.3950e-02,  3.8585e-02],\n",
       "          [ 3.5528e-02,  3.4417e-02,  3.6093e-02,  ...,  3.4954e-02,\n",
       "            4.0088e-02,  4.2032e-02],\n",
       "          [ 3.5104e-02,  3.5843e-02,  3.6798e-02,  ...,  3.2825e-02,\n",
       "            3.5363e-02,  3.9438e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.3727e-02,  2.3055e-02,  2.4257e-02,  ...,  2.1465e-02,\n",
       "            2.1104e-02,  1.3552e-02],\n",
       "          [ 5.3214e-02,  3.0389e-02,  3.0706e-02,  ...,  3.0389e-02,\n",
       "            3.0127e-02,  2.6344e-02],\n",
       "          [ 5.4351e-02,  2.9868e-02,  3.0225e-02,  ...,  3.3362e-02,\n",
       "            3.3163e-02,  2.7983e-02],\n",
       "          ...,\n",
       "          [ 1.7717e-02,  3.4466e-02,  3.2731e-02,  ...,  3.1680e-02,\n",
       "            3.4655e-02,  3.4628e-02],\n",
       "          [ 1.6433e-02,  3.2599e-02,  3.1570e-02,  ...,  2.9566e-02,\n",
       "            3.4940e-02,  3.9123e-02],\n",
       "          [ 1.7965e-02,  2.6086e-02,  2.8347e-02,  ...,  2.5810e-02,\n",
       "            2.5377e-02,  3.1489e-02]],\n",
       "\n",
       "         [[ 2.7468e-02,  3.5201e-02,  3.6988e-02,  ...,  3.6762e-02,\n",
       "            3.7031e-02,  4.9399e-02],\n",
       "          [ 3.0765e-02,  3.5891e-02,  3.7226e-02,  ...,  3.6536e-02,\n",
       "            3.6550e-02,  4.1913e-02],\n",
       "          [ 3.1524e-02,  3.6782e-02,  3.7645e-02,  ...,  3.1195e-02,\n",
       "            3.3802e-02,  4.2141e-02],\n",
       "          ...,\n",
       "          [ 4.2810e-02,  3.8713e-02,  3.6330e-02,  ...,  3.9769e-02,\n",
       "            3.7326e-02,  3.8368e-02],\n",
       "          [ 4.2646e-02,  4.0217e-02,  4.2543e-02,  ...,  3.9371e-02,\n",
       "            3.5323e-02,  3.1189e-02],\n",
       "          [ 4.8348e-02,  5.0201e-02,  4.6191e-02,  ...,  4.9049e-02,\n",
       "            5.1120e-02,  4.4547e-02]],\n",
       "\n",
       "         [[ 2.0034e-01,  2.0393e-01,  2.0520e-01,  ...,  1.9594e-01,\n",
       "            1.9552e-01,  1.8805e-01],\n",
       "          [ 2.0734e-01,  2.1280e-01,  2.1313e-01,  ...,  1.9867e-01,\n",
       "            1.9806e-01,  1.9037e-01],\n",
       "          [ 2.0680e-01,  2.1231e-01,  2.1252e-01,  ...,  1.9669e-01,\n",
       "            1.9796e-01,  1.8999e-01],\n",
       "          ...,\n",
       "          [ 1.8715e-01,  1.9597e-01,  1.9752e-01,  ...,  1.9445e-01,\n",
       "            1.9742e-01,  1.8827e-01],\n",
       "          [ 1.8522e-01,  1.9356e-01,  1.9398e-01,  ...,  1.9182e-01,\n",
       "            1.9409e-01,  1.8714e-01],\n",
       "          [ 1.7839e-01,  1.8136e-01,  1.8121e-01,  ...,  1.7863e-01,\n",
       "            1.7883e-01,  1.7652e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2117e-01,  1.3361e-01,  1.3797e-01,  ...,  1.3280e-01,\n",
       "            1.3466e-01,  1.2469e-01],\n",
       "          [ 1.0084e-01,  1.0430e-01,  1.0607e-01,  ...,  1.1059e-01,\n",
       "            1.1094e-01,  1.0629e-01],\n",
       "          [ 9.2731e-02,  9.2621e-02,  9.2562e-02,  ...,  8.7130e-02,\n",
       "            9.6170e-02,  9.7769e-02],\n",
       "          ...,\n",
       "          [ 1.0037e-01,  1.0865e-01,  1.1557e-01,  ...,  8.9417e-02,\n",
       "            9.6356e-02,  1.0044e-01],\n",
       "          [ 9.8223e-02,  1.0670e-01,  1.1711e-01,  ...,  9.5571e-02,\n",
       "            1.0207e-01,  1.0333e-01],\n",
       "          [ 8.0515e-02,  7.2469e-02,  7.3821e-02,  ...,  7.4014e-02,\n",
       "            7.2670e-02,  7.7991e-02]],\n",
       "\n",
       "         [[ 5.0590e-02,  4.6558e-02,  4.5444e-02,  ...,  3.4050e-02,\n",
       "            3.6693e-02,  3.6227e-02],\n",
       "          [ 4.5760e-02,  4.6212e-02,  4.2359e-02,  ...,  5.5476e-02,\n",
       "            5.1880e-02,  4.6374e-02],\n",
       "          [ 2.9041e-02,  3.1960e-02,  3.8261e-02,  ...,  3.3290e-02,\n",
       "            3.8154e-02,  4.1742e-02],\n",
       "          ...,\n",
       "          [ 3.6580e-02,  3.7993e-02,  4.4968e-02,  ...,  3.8633e-02,\n",
       "            4.1386e-02,  3.8950e-02],\n",
       "          [ 4.2369e-02,  5.0268e-02,  5.0802e-02,  ...,  4.0654e-02,\n",
       "            4.8819e-02,  5.1999e-02],\n",
       "          [ 6.3670e-02,  4.8745e-02,  4.6340e-02,  ...,  5.0279e-02,\n",
       "            4.6437e-02,  2.9922e-02]],\n",
       "\n",
       "         [[ 2.3912e-02,  3.3985e-02,  3.4323e-02,  ...,  3.2081e-02,\n",
       "            3.1342e-02,  9.2327e-02],\n",
       "          [ 2.6483e-02,  3.3855e-02,  3.1410e-02,  ...,  3.2939e-02,\n",
       "            3.4496e-02,  9.6683e-02],\n",
       "          [ 2.6419e-02,  3.1107e-02,  3.2516e-02,  ...,  3.4530e-02,\n",
       "            3.3723e-02,  9.7744e-02],\n",
       "          ...,\n",
       "          [ 2.8300e-02,  4.0381e-02,  3.2897e-02,  ...,  3.1561e-02,\n",
       "            3.3213e-02,  7.6066e-02],\n",
       "          [ 2.8505e-02,  3.3702e-02,  3.2474e-02,  ...,  2.8413e-02,\n",
       "            3.0747e-02,  9.1514e-02],\n",
       "          [ 3.2212e-02,  3.4094e-02,  3.4779e-02,  ...,  3.1648e-02,\n",
       "            2.9396e-02,  6.9177e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1025e-03,  4.8284e-02,  4.5913e-02,  ...,  4.1030e-02,\n",
       "            4.0592e-02,  5.2390e-02],\n",
       "          [-1.8336e-02,  2.8468e-02,  3.2916e-02,  ...,  3.4350e-02,\n",
       "            3.2340e-02,  3.5710e-02],\n",
       "          [-1.1811e-02,  2.8136e-02,  2.7570e-02,  ...,  1.8918e-02,\n",
       "            3.7120e-02,  3.3114e-02],\n",
       "          ...,\n",
       "          [-1.9920e-02,  3.9194e-02,  6.5978e-02,  ...,  2.6508e-02,\n",
       "            3.5954e-02,  4.1332e-02],\n",
       "          [-6.9990e-03,  2.6760e-02,  3.8402e-02,  ...,  3.0345e-02,\n",
       "            2.6455e-02,  3.8806e-02],\n",
       "          [-1.2084e-02,  1.4950e-02,  9.4688e-03,  ...,  2.0937e-02,\n",
       "            1.2162e-02,  1.6645e-02]],\n",
       "\n",
       "         [[ 6.1848e-02,  4.6054e-02,  4.3219e-02,  ...,  4.6124e-02,\n",
       "            4.6178e-02,  2.7703e-02],\n",
       "          [ 5.7946e-02,  4.8051e-02,  4.2707e-02,  ...,  3.4401e-02,\n",
       "            3.6778e-02,  3.2584e-02],\n",
       "          [ 5.0903e-02,  5.0389e-02,  4.8349e-02,  ...,  5.6410e-02,\n",
       "            4.2243e-02,  3.5948e-02],\n",
       "          ...,\n",
       "          [ 6.0793e-02,  4.5697e-02,  1.5743e-02,  ...,  4.9482e-02,\n",
       "            4.0959e-02,  2.7640e-02],\n",
       "          [ 4.3297e-02,  4.3981e-02,  4.0385e-02,  ...,  3.8464e-02,\n",
       "            4.1903e-02,  3.1987e-02],\n",
       "          [ 7.6295e-02,  8.0460e-02,  8.5402e-02,  ...,  7.1656e-02,\n",
       "            7.6767e-02,  6.6381e-02]],\n",
       "\n",
       "         [[ 2.0829e-01,  2.2075e-01,  2.1618e-01,  ...,  1.7038e-01,\n",
       "            1.8291e-01,  1.8957e-01],\n",
       "          [ 2.1329e-01,  2.3366e-01,  2.3524e-01,  ...,  1.9272e-01,\n",
       "            2.0982e-01,  2.0697e-01],\n",
       "          [ 1.9204e-01,  2.0986e-01,  2.1810e-01,  ...,  2.0639e-01,\n",
       "            2.3097e-01,  2.1810e-01],\n",
       "          ...,\n",
       "          [ 1.7769e-01,  1.6533e-01,  1.4667e-01,  ...,  1.3185e-01,\n",
       "            1.3441e-01,  1.5363e-01],\n",
       "          [ 1.8014e-01,  1.9067e-01,  1.8217e-01,  ...,  1.2905e-01,\n",
       "            1.5485e-01,  1.7628e-01],\n",
       "          [ 1.8449e-01,  1.9800e-01,  2.0209e-01,  ...,  1.4511e-01,\n",
       "            1.7499e-01,  1.8736e-01]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakenorm(model.features.conv0(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.2091e-02,  6.0702e-02,  5.7073e-02,  ...,  6.3750e-02,\n",
       "            6.5373e-02,  7.4252e-02],\n",
       "          [ 8.4029e-02,  7.8842e-02,  7.7389e-02,  ...,  8.0532e-02,\n",
       "            7.8855e-02,  8.3762e-02],\n",
       "          [ 8.8639e-02,  8.5900e-02,  8.7171e-02,  ...,  9.1912e-02,\n",
       "            8.6170e-02,  8.7114e-02],\n",
       "          ...,\n",
       "          [ 1.0504e-01,  1.2451e-01,  1.4050e-01,  ...,  4.4827e-02,\n",
       "            4.6780e-02,  5.9309e-02],\n",
       "          [ 1.1707e-01,  1.3267e-01,  1.4594e-01,  ...,  7.0831e-02,\n",
       "            8.2864e-02,  9.0184e-02],\n",
       "          [ 1.1123e-01,  1.0000e-01,  7.9482e-02,  ...,  1.3722e-01,\n",
       "            1.3630e-01,  1.2440e-01]],\n",
       "\n",
       "         [[ 3.1965e-02,  3.4989e-02,  3.4689e-02,  ...,  3.8270e-02,\n",
       "            3.7586e-02,  4.1807e-02],\n",
       "          [ 3.9298e-02,  3.5787e-02,  3.6537e-02,  ...,  3.6678e-02,\n",
       "            3.7052e-02,  3.7157e-02],\n",
       "          [ 3.8765e-02,  3.6051e-02,  3.6885e-02,  ...,  4.1100e-02,\n",
       "            3.6134e-02,  3.5950e-02],\n",
       "          ...,\n",
       "          [ 9.9830e-03,  2.9844e-02,  1.0281e-01,  ...,  4.1728e-03,\n",
       "            4.0212e-02,  3.0316e-02],\n",
       "          [ 1.0660e-01,  1.1653e-01,  6.3773e-02,  ...,  4.0200e-02,\n",
       "            3.6978e-02,  3.4877e-02],\n",
       "          [ 2.2175e-02,  1.5223e-02,  1.6266e-02,  ...,  3.3099e-02,\n",
       "            3.4106e-02,  5.7144e-02]],\n",
       "\n",
       "         [[ 4.6259e-02,  3.5564e-02,  3.3355e-02,  ...,  3.2653e-02,\n",
       "            3.0900e-02, -1.8325e-02],\n",
       "          [ 4.3009e-02,  3.6221e-02,  3.4473e-02,  ...,  3.4934e-02,\n",
       "            3.2757e-02, -2.7313e-02],\n",
       "          [ 4.3638e-02,  3.7452e-02,  3.5221e-02,  ...,  3.3918e-02,\n",
       "            3.3231e-02, -3.6974e-02],\n",
       "          ...,\n",
       "          [ 6.6551e-02,  3.9354e-02,  1.9255e-02,  ...,  3.0943e-02,\n",
       "            3.0588e-02, -5.8325e-02],\n",
       "          [ 4.4546e-02,  3.4517e-02,  3.8315e-02,  ...,  3.3948e-02,\n",
       "            3.2117e-02, -6.5042e-02],\n",
       "          [ 2.3106e-02,  3.4375e-02,  3.3253e-02,  ...,  3.2812e-02,\n",
       "            3.0002e-02, -2.8714e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.3127e-02,  1.3364e-02,  1.7393e-02,  ...,  1.6601e-02,\n",
       "            1.8521e-02,  1.4900e-02],\n",
       "          [ 7.1893e-02,  2.4897e-02,  2.6880e-02,  ...,  2.0009e-02,\n",
       "            2.3457e-02,  2.1853e-02],\n",
       "          [ 7.6471e-02,  2.3090e-02,  2.4564e-02,  ...,  3.2852e-02,\n",
       "            2.0914e-02,  2.0941e-02],\n",
       "          ...,\n",
       "          [ 1.0880e-01,  6.9188e-03,  3.8859e-02,  ...,  3.1268e-02,\n",
       "            2.0429e-02,  8.6793e-03],\n",
       "          [ 9.1274e-02, -2.0921e-02, -1.0940e-02,  ...,  2.2946e-02,\n",
       "            3.1304e-02,  2.5884e-02],\n",
       "          [ 8.5925e-02,  1.0451e-02, -2.2951e-02,  ...,  4.7462e-02,\n",
       "            4.8047e-02,  5.1208e-02]],\n",
       "\n",
       "         [[ 1.9811e-02,  3.5033e-02,  3.8132e-02,  ...,  4.1763e-02,\n",
       "            4.0610e-02,  4.8607e-02],\n",
       "          [ 2.4831e-02,  3.6234e-02,  3.8511e-02,  ...,  4.1901e-02,\n",
       "            4.1682e-02,  4.4566e-02],\n",
       "          [ 2.6373e-02,  3.8456e-02,  3.9387e-02,  ...,  2.7351e-02,\n",
       "            4.1804e-02,  4.6444e-02],\n",
       "          ...,\n",
       "          [ 6.0528e-03,  8.0044e-03, -3.4841e-02,  ...,  4.6588e-02,\n",
       "            3.4512e-02,  4.9890e-02],\n",
       "          [ 3.5890e-02,  7.1237e-02,  8.2953e-02,  ...,  3.5140e-02,\n",
       "            3.1666e-02,  4.0539e-02],\n",
       "          [ 5.8024e-03,  2.6113e-02,  6.9170e-02,  ..., -1.5663e-02,\n",
       "           -1.3137e-02,  5.0780e-04]],\n",
       "\n",
       "         [[ 2.4533e-01,  2.5793e-01,  2.6767e-01,  ...,  2.9066e-01,\n",
       "            2.9222e-01,  2.4345e-01],\n",
       "          [ 2.5404e-01,  2.6795e-01,  2.8429e-01,  ...,  3.1778e-01,\n",
       "            3.2545e-01,  2.6214e-01],\n",
       "          [ 2.3129e-01,  2.4066e-01,  2.5536e-01,  ...,  2.7391e-01,\n",
       "            3.0273e-01,  2.4919e-01],\n",
       "          ...,\n",
       "          [ 1.7423e-01,  1.6169e-01,  1.9072e-01,  ...,  9.3827e-02,\n",
       "            1.1476e-01,  1.5308e-01],\n",
       "          [ 1.8865e-01,  1.6646e-01,  1.7345e-01,  ...,  7.4167e-02,\n",
       "            8.7884e-02,  1.4798e-01],\n",
       "          [ 2.1210e-01,  1.9201e-01,  1.9964e-01,  ...,  1.5353e-01,\n",
       "            1.5966e-01,  1.8735e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.3834e-02,  7.6597e-02,  7.2175e-02,  ...,  9.4943e-02,\n",
       "            1.0193e-01,  1.0334e-01],\n",
       "          [ 9.2020e-02,  9.0922e-02,  9.0981e-02,  ...,  1.0839e-01,\n",
       "            1.0752e-01,  1.0403e-01],\n",
       "          [ 9.7484e-02,  9.9699e-02,  1.0151e-01,  ...,  1.0967e-01,\n",
       "            1.0783e-01,  1.0313e-01],\n",
       "          ...,\n",
       "          [ 9.7462e-02,  9.8237e-02,  9.4674e-02,  ...,  8.9265e-02,\n",
       "            9.1131e-02,  9.3057e-02],\n",
       "          [ 9.5829e-02,  9.6096e-02,  9.5979e-02,  ...,  9.5372e-02,\n",
       "            9.6986e-02,  9.7045e-02],\n",
       "          [ 7.3101e-02,  6.2555e-02,  5.9589e-02,  ...,  6.2111e-02,\n",
       "            6.1367e-02,  7.0079e-02]],\n",
       "\n",
       "         [[ 3.2658e-02,  3.3781e-02,  3.5887e-02,  ...,  5.7683e-02,\n",
       "            5.1635e-02,  3.7091e-02],\n",
       "          [ 3.9469e-02,  3.8419e-02,  3.9526e-02,  ...,  3.8373e-02,\n",
       "            4.4339e-02,  5.2308e-02],\n",
       "          [ 3.9528e-02,  3.8361e-02,  3.9415e-02,  ...,  4.5418e-02,\n",
       "            3.6477e-02,  4.3360e-02],\n",
       "          ...,\n",
       "          [ 4.0771e-02,  4.5964e-02,  4.7302e-02,  ...,  3.9811e-02,\n",
       "            4.1828e-02,  4.2978e-02],\n",
       "          [ 4.2432e-02,  4.1474e-02,  4.1926e-02,  ...,  3.9740e-02,\n",
       "            3.9495e-02,  4.1393e-02],\n",
       "          [ 6.7088e-02,  4.8285e-02,  4.4648e-02,  ...,  5.2331e-02,\n",
       "            5.0269e-02,  2.7712e-02]],\n",
       "\n",
       "         [[ 3.8411e-02,  3.3193e-02,  3.2766e-02,  ...,  3.3081e-02,\n",
       "            4.4709e-02,  5.2540e-02],\n",
       "          [ 3.8162e-02,  3.4323e-02,  3.4967e-02,  ...,  1.6953e-02,\n",
       "            2.8160e-02,  4.8641e-02],\n",
       "          [ 3.6807e-02,  3.5040e-02,  3.5583e-02,  ..., -1.3876e-03,\n",
       "            3.5592e-02,  6.4628e-02],\n",
       "          ...,\n",
       "          [ 2.5842e-02,  3.3725e-02,  3.0406e-02,  ...,  3.1870e-02,\n",
       "            3.3023e-02,  1.2064e-01],\n",
       "          [ 2.7191e-02,  2.9992e-02,  2.8907e-02,  ...,  3.2302e-02,\n",
       "            3.1397e-02,  1.2711e-01],\n",
       "          [ 3.3255e-02,  3.2332e-02,  3.2606e-02,  ...,  3.2977e-02,\n",
       "            3.3074e-02,  9.6099e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.1296e-02,  2.9530e-02,  2.7237e-02,  ...,  1.8074e-02,\n",
       "            2.3365e-02,  3.9594e-02],\n",
       "          [ 4.6687e-02,  3.6576e-02,  3.5771e-02,  ...,  2.5872e-02,\n",
       "            1.8520e-02,  4.3784e-02],\n",
       "          [ 4.5927e-02,  3.6198e-02,  3.5033e-02,  ...,  3.3252e-02,\n",
       "            1.3129e-02,  4.6512e-02],\n",
       "          ...,\n",
       "          [-2.4071e-02,  3.3893e-02,  4.1638e-02,  ...,  3.2711e-02,\n",
       "            3.3644e-02,  3.3552e-02],\n",
       "          [-2.4142e-02,  3.5370e-02,  3.6260e-02,  ...,  3.2806e-02,\n",
       "            3.3109e-02,  3.3301e-02],\n",
       "          [-2.6721e-02,  1.0369e-02,  1.6621e-02,  ...,  1.5516e-02,\n",
       "            1.6376e-02,  1.1656e-02]],\n",
       "\n",
       "         [[ 2.6359e-02,  2.9380e-02,  3.1048e-02,  ...,  3.7405e-02,\n",
       "            3.7734e-02,  3.3140e-02],\n",
       "          [ 3.1384e-02,  3.2821e-02,  3.2673e-02,  ...,  3.8410e-02,\n",
       "            3.7840e-02,  2.6489e-02],\n",
       "          [ 3.1072e-02,  3.2084e-02,  3.2429e-02,  ...,  3.4746e-02,\n",
       "            3.9608e-02,  2.7992e-02],\n",
       "          ...,\n",
       "          [ 5.3964e-02,  4.2742e-02,  3.7987e-02,  ...,  4.3808e-02,\n",
       "            4.1437e-02,  3.3733e-02],\n",
       "          [ 5.4008e-02,  4.2209e-02,  3.9772e-02,  ...,  4.0664e-02,\n",
       "            4.1726e-02,  3.4053e-02],\n",
       "          [ 8.2102e-02,  8.8896e-02,  8.5795e-02,  ...,  8.3662e-02,\n",
       "            8.4304e-02,  7.3349e-02]],\n",
       "\n",
       "         [[ 2.9270e-01,  3.2488e-01,  3.3296e-01,  ...,  3.1021e-01,\n",
       "            2.9425e-01,  2.4928e-01],\n",
       "          [ 3.3086e-01,  3.7672e-01,  3.8425e-01,  ...,  3.5159e-01,\n",
       "            3.3542e-01,  2.7258e-01],\n",
       "          [ 3.3175e-01,  3.7597e-01,  3.7819e-01,  ...,  3.4061e-01,\n",
       "            3.2682e-01,  2.6475e-01],\n",
       "          ...,\n",
       "          [ 2.1011e-01,  2.5396e-01,  2.5480e-01,  ...,  2.3924e-01,\n",
       "            2.3520e-01,  2.2426e-01],\n",
       "          [ 2.2616e-01,  2.5462e-01,  2.4948e-01,  ...,  2.4216e-01,\n",
       "            2.4050e-01,  2.2601e-01],\n",
       "          [ 2.1224e-01,  2.2856e-01,  2.2460e-01,  ...,  2.1652e-01,\n",
       "            2.1643e-01,  2.0768e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3454e-01,  1.4882e-01,  1.4234e-01,  ...,  1.6125e-01,\n",
       "            1.6134e-01,  1.4296e-01],\n",
       "          [ 1.0748e-01,  1.1089e-01,  1.0621e-01,  ...,  1.1515e-01,\n",
       "            1.1528e-01,  1.0961e-01],\n",
       "          [ 9.5377e-02,  9.7360e-02,  9.6044e-02,  ...,  9.5691e-02,\n",
       "            9.5602e-02,  9.5529e-02],\n",
       "          ...,\n",
       "          [ 9.5235e-02,  9.5078e-02,  9.3345e-02,  ...,  8.0364e-02,\n",
       "            8.9826e-02,  9.5553e-02],\n",
       "          [ 9.5459e-02,  9.4695e-02,  8.6022e-02,  ...,  7.0942e-02,\n",
       "            8.0790e-02,  9.2450e-02],\n",
       "          [ 6.4716e-02,  4.8914e-02,  4.2788e-02,  ...,  5.1417e-02,\n",
       "            4.4359e-02,  5.6244e-02]],\n",
       "\n",
       "         [[ 5.9908e-02,  4.5329e-02,  3.2678e-02,  ...,  4.8621e-02,\n",
       "            4.8647e-02,  3.3591e-02],\n",
       "          [ 4.1337e-02,  4.2562e-02,  4.1335e-02,  ...,  4.4123e-02,\n",
       "            4.4177e-02,  4.4890e-02],\n",
       "          [ 4.2114e-02,  4.0658e-02,  4.1937e-02,  ...,  4.3729e-02,\n",
       "            4.3653e-02,  4.3151e-02],\n",
       "          ...,\n",
       "          [ 4.2047e-02,  4.3539e-02,  4.2986e-02,  ...,  4.0122e-02,\n",
       "            4.0963e-02,  4.3060e-02],\n",
       "          [ 4.2133e-02,  4.4279e-02,  5.0039e-02,  ...,  3.5046e-02,\n",
       "            3.8056e-02,  4.1502e-02],\n",
       "          [ 7.7457e-02,  5.1000e-02,  9.9536e-03,  ...,  5.1343e-02,\n",
       "            6.2698e-02,  2.2253e-02]],\n",
       "\n",
       "         [[ 1.5320e-02,  1.1847e-02,  1.8928e-02,  ...,  3.4152e-02,\n",
       "            3.4101e-02,  1.5484e-01],\n",
       "          [ 2.1586e-02,  7.7230e-03,  1.5618e-02,  ...,  3.2061e-02,\n",
       "            3.2138e-02,  1.6066e-01],\n",
       "          [ 2.1240e-02,  5.8261e-04,  4.1913e-02,  ...,  3.2193e-02,\n",
       "            3.2382e-02,  1.6211e-01],\n",
       "          ...,\n",
       "          [ 2.1662e-02,  3.0942e-02,  2.4162e-02,  ...,  3.5558e-02,\n",
       "            3.2113e-02,  1.6371e-01],\n",
       "          [ 2.2085e-02,  2.9019e-02,  3.4337e-02,  ...,  3.3743e-02,\n",
       "            3.0364e-02,  1.6317e-01],\n",
       "          [ 3.0978e-02,  2.7583e-02,  4.3977e-02,  ...,  1.9259e-02,\n",
       "            3.1488e-02,  1.1611e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6451e-02,  6.1889e-02,  7.6521e-02,  ...,  5.5014e-02,\n",
       "            5.5526e-02,  7.1936e-02],\n",
       "          [-4.7213e-02,  3.2208e-02,  6.3080e-02,  ...,  3.2960e-02,\n",
       "            3.3713e-02,  4.0370e-02],\n",
       "          [-4.5051e-02,  3.0215e-02,  6.1461e-02,  ...,  3.4668e-02,\n",
       "            3.5409e-02,  3.5310e-02],\n",
       "          ...,\n",
       "          [-4.4380e-02,  3.4020e-02,  3.5273e-02,  ...,  7.8887e-03,\n",
       "            3.3704e-02,  3.5000e-02],\n",
       "          [-4.4447e-02,  3.4301e-02,  3.7924e-02,  ..., -1.1717e-02,\n",
       "            7.4535e-03,  3.7350e-02],\n",
       "          [-4.5714e-02, -5.6332e-04,  1.5568e-02,  ..., -6.7845e-05,\n",
       "           -2.8708e-02, -1.7059e-04]],\n",
       "\n",
       "         [[ 7.5534e-02,  4.3130e-02,  2.7802e-02,  ...,  4.4410e-02,\n",
       "            4.4274e-02,  1.6505e-02],\n",
       "          [ 6.4309e-02,  4.4999e-02,  2.9680e-02,  ...,  4.5575e-02,\n",
       "            4.5284e-02,  3.3297e-02],\n",
       "          [ 6.0651e-02,  4.3759e-02,  2.7222e-02,  ...,  4.3161e-02,\n",
       "            4.3131e-02,  3.3172e-02],\n",
       "          ...,\n",
       "          [ 6.0260e-02,  4.6110e-02,  4.2193e-02,  ...,  6.4648e-02,\n",
       "            4.6320e-02,  3.2789e-02],\n",
       "          [ 6.0482e-02,  4.6123e-02,  4.4476e-02,  ...,  7.6721e-02,\n",
       "            6.3117e-02,  3.3198e-02],\n",
       "          [ 9.7951e-02,  1.0755e-01,  8.5717e-02,  ...,  8.0804e-02,\n",
       "            1.1172e-01,  9.3357e-02]],\n",
       "\n",
       "         [[ 1.9654e-01,  2.0110e-01,  1.7782e-01,  ...,  2.1029e-01,\n",
       "            2.1057e-01,  2.0800e-01],\n",
       "          [ 2.0231e-01,  2.0955e-01,  1.7999e-01,  ...,  2.2929e-01,\n",
       "            2.2858e-01,  2.1664e-01],\n",
       "          [ 1.9754e-01,  2.0694e-01,  1.7580e-01,  ...,  2.2123e-01,\n",
       "            2.2162e-01,  2.1399e-01],\n",
       "          ...,\n",
       "          [ 1.9689e-01,  2.2266e-01,  2.0440e-01,  ...,  2.0472e-01,\n",
       "            2.2260e-01,  2.1901e-01],\n",
       "          [ 1.9635e-01,  2.2159e-01,  1.8843e-01,  ...,  1.8120e-01,\n",
       "            2.0509e-01,  2.1770e-01],\n",
       "          [ 1.8780e-01,  1.9762e-01,  1.7648e-01,  ...,  1.7922e-01,\n",
       "            1.8426e-01,  1.9800e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.0854e-01,  1.1231e-01,  1.0825e-01,  ...,  7.8561e-02,\n",
       "            7.2160e-02,  7.5468e-02],\n",
       "          [ 9.4930e-02,  9.8820e-02,  1.0158e-01,  ...,  1.0419e-01,\n",
       "            1.0115e-01,  9.6890e-02],\n",
       "          [ 9.5577e-02,  1.0066e-01,  1.0961e-01,  ...,  1.3086e-01,\n",
       "            1.3721e-01,  1.2749e-01],\n",
       "          ...,\n",
       "          [ 8.8750e-02,  8.8245e-02,  8.5305e-02,  ...,  8.9094e-02,\n",
       "            7.3475e-02,  6.8229e-02],\n",
       "          [ 9.0468e-02,  9.0691e-02,  9.6274e-02,  ...,  1.1043e-01,\n",
       "            1.0245e-01,  9.5541e-02],\n",
       "          [ 8.8587e-02,  8.7053e-02,  9.0588e-02,  ...,  7.6467e-02,\n",
       "            9.0010e-02,  9.7841e-02]],\n",
       "\n",
       "         [[ 5.4797e-02,  5.6686e-02,  5.3529e-02,  ..., -7.4379e-02,\n",
       "           -3.2726e-02,  4.0013e-02],\n",
       "          [ 2.6610e-02,  3.5887e-02,  4.4902e-02,  ...,  1.6563e-01,\n",
       "            9.8251e-02,  7.4562e-03],\n",
       "          [ 4.7246e-02,  3.1890e-02,  3.3663e-02,  ..., -8.3904e-03,\n",
       "           -8.9659e-03,  8.5545e-02],\n",
       "          ...,\n",
       "          [ 2.5957e-02,  2.6892e-02,  3.8145e-02,  ...,  2.4970e-02,\n",
       "           -5.2996e-03,  1.3235e-02],\n",
       "          [ 4.1593e-02,  4.0292e-02,  1.5343e-02,  ...,  9.4005e-02,\n",
       "            7.6989e-02,  4.7151e-02],\n",
       "          [ 4.4288e-02,  5.3819e-02,  6.7474e-02,  ...,  2.0712e-02,\n",
       "            4.0260e-02,  5.1403e-02]],\n",
       "\n",
       "         [[ 8.9342e-03, -4.3373e-03,  1.7688e-02,  ...,  4.0269e-02,\n",
       "            2.6676e-02, -2.5863e-02],\n",
       "          [ 2.4945e-02, -7.0568e-04,  3.4777e-02,  ...,  1.8695e-02,\n",
       "            2.2489e-02,  2.3122e-02],\n",
       "          [ 1.2142e-02, -4.4353e-02,  4.2441e-02,  ...,  4.2577e-02,\n",
       "            4.4076e-02,  1.1268e-01],\n",
       "          ...,\n",
       "          [ 2.7085e-02, -1.4004e-02,  2.5108e-02,  ...,  2.3807e-02,\n",
       "            4.2852e-02,  1.3975e-01],\n",
       "          [ 4.5617e-02, -1.1508e-03,  5.3149e-02,  ...,  3.4274e-02,\n",
       "            7.3797e-02,  9.7670e-02],\n",
       "          [ 4.0112e-02,  2.5464e-02,  4.7071e-02,  ...,  3.8537e-02,\n",
       "            3.0013e-02,  6.3516e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0223e-02,  5.0581e-02,  5.8413e-02,  ...,  3.2428e-02,\n",
       "            4.7523e-02,  1.3518e-02],\n",
       "          [-3.6765e-04,  3.2495e-02,  4.1439e-02,  ...,  5.9589e-02,\n",
       "            6.2968e-02,  3.6673e-02],\n",
       "          [ 4.6477e-03,  4.7322e-02,  2.4316e-02,  ...,  7.6252e-02,\n",
       "            7.3486e-02,  5.1261e-02],\n",
       "          ...,\n",
       "          [-2.0739e-03,  3.9782e-02,  3.2850e-02,  ...,  1.1549e-01,\n",
       "           -5.3070e-03, -4.3949e-02],\n",
       "          [ 6.5259e-03,  4.8396e-02,  2.9510e-02,  ...,  8.9544e-02,\n",
       "            9.7499e-02,  1.1327e-02],\n",
       "          [ 6.8385e-03,  3.2753e-02,  2.7606e-02,  ...,  1.9786e-02,\n",
       "            3.7199e-02,  3.7093e-02]],\n",
       "\n",
       "         [[ 5.7425e-02,  3.7512e-02,  1.9052e-02,  ...,  6.3726e-02,\n",
       "            4.2781e-02,  5.2879e-02],\n",
       "          [ 4.6968e-02,  4.4612e-02,  3.4144e-02,  ..., -2.0549e-02,\n",
       "           -3.3547e-03,  1.8231e-02],\n",
       "          [ 3.4713e-02,  3.2611e-02,  3.5622e-02,  ...,  1.9104e-02,\n",
       "            1.6421e-02,  7.5595e-03],\n",
       "          ...,\n",
       "          [ 5.0530e-02,  4.8510e-02,  4.5412e-02,  ..., -4.9424e-02,\n",
       "            5.7836e-02,  1.0478e-01],\n",
       "          [ 3.7354e-02,  2.8384e-02,  2.9438e-02,  ...,  3.7596e-02,\n",
       "           -3.9356e-02, -2.8351e-03],\n",
       "          [ 5.8070e-02,  5.8976e-02,  5.6016e-02,  ...,  7.1090e-02,\n",
       "            8.5973e-02,  5.6739e-02]],\n",
       "\n",
       "         [[ 1.6318e-01,  1.4649e-01,  1.2610e-01,  ...,  1.6521e-02,\n",
       "           -9.9585e-02, -5.8991e-02],\n",
       "          [ 1.8971e-01,  1.7851e-01,  1.7788e-01,  ..., -6.7008e-02,\n",
       "           -1.9605e-01, -1.2705e-01],\n",
       "          [ 1.8778e-01,  1.7877e-01,  2.0060e-01,  ...,  1.2284e-02,\n",
       "           -6.6301e-02,  3.1143e-02],\n",
       "          ...,\n",
       "          [ 7.8446e-02,  4.0818e-02,  3.5179e-02,  ...,  4.8801e-02,\n",
       "            5.1440e-02,  1.2595e-01],\n",
       "          [-4.7136e-03, -3.3356e-02,  9.0511e-03,  ...,  5.0023e-02,\n",
       "            2.4060e-03,  7.3718e-02],\n",
       "          [ 3.5370e-02,  1.9129e-02,  6.7274e-02,  ...,  4.1972e-02,\n",
       "           -2.0749e-02,  6.0480e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.5830e-02,  6.5665e-02,  6.1493e-02,  ...,  5.0454e-02,\n",
       "            4.9491e-02,  6.1754e-02],\n",
       "          [ 8.7056e-02,  8.3087e-02,  8.1660e-02,  ...,  7.7886e-02,\n",
       "            7.7526e-02,  8.2185e-02],\n",
       "          [ 9.2320e-02,  9.1223e-02,  9.0802e-02,  ...,  9.5498e-02,\n",
       "            9.4963e-02,  9.2012e-02],\n",
       "          ...,\n",
       "          [ 9.5664e-02,  9.5238e-02,  9.5755e-02,  ...,  9.7615e-02,\n",
       "            9.8643e-02,  9.7792e-02],\n",
       "          [ 9.4096e-02,  9.4882e-02,  9.6895e-02,  ...,  9.7690e-02,\n",
       "            9.9108e-02,  9.8882e-02],\n",
       "          [ 8.6927e-02,  8.3601e-02,  8.2943e-02,  ...,  8.6419e-02,\n",
       "            8.7755e-02,  9.0997e-02]],\n",
       "\n",
       "         [[ 3.0624e-02,  3.3252e-02,  3.4430e-02,  ...,  3.2590e-02,\n",
       "            3.1869e-02,  4.1437e-02],\n",
       "          [ 3.9607e-02,  3.6940e-02,  3.6869e-02,  ...,  3.4265e-02,\n",
       "            3.5024e-02,  3.5171e-02],\n",
       "          [ 3.8456e-02,  3.6555e-02,  3.6785e-02,  ...,  3.5512e-02,\n",
       "            3.9548e-02,  3.6746e-02],\n",
       "          ...,\n",
       "          [ 4.2194e-02,  4.5957e-02,  4.1674e-02,  ...,  3.5305e-02,\n",
       "            3.3449e-02,  2.9838e-02],\n",
       "          [ 4.2684e-02,  3.6860e-02,  3.8999e-02,  ...,  5.0686e-02,\n",
       "            5.0383e-02,  4.7157e-02],\n",
       "          [ 4.4157e-02,  5.1222e-02,  4.2787e-02,  ...,  3.8329e-02,\n",
       "            4.6124e-02,  3.6380e-02]],\n",
       "\n",
       "         [[ 4.3246e-02,  3.4650e-02,  3.3362e-02,  ...,  3.3098e-02,\n",
       "            3.2625e-02, -5.1008e-02],\n",
       "          [ 4.1202e-02,  3.5222e-02,  3.5161e-02,  ...,  3.4260e-02,\n",
       "            3.4592e-02, -5.8254e-02],\n",
       "          [ 4.1606e-02,  3.5680e-02,  3.5482e-02,  ...,  2.4834e-02,\n",
       "            3.5152e-02, -6.3308e-02],\n",
       "          ...,\n",
       "          [ 3.3360e-02,  3.7025e-02,  3.9037e-02,  ...,  2.9657e-02,\n",
       "            3.3239e-02,  4.1934e-02],\n",
       "          [ 3.6199e-02,  3.4116e-02,  3.7259e-02,  ...,  3.5123e-02,\n",
       "            4.4752e-02,  4.8400e-02],\n",
       "          [ 3.5404e-02,  3.6790e-02,  3.8582e-02,  ...,  3.1129e-02,\n",
       "            3.5889e-02,  4.3535e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.0264e-02,  1.8803e-02,  2.0634e-02,  ...,  1.6384e-02,\n",
       "            1.5835e-02,  4.3412e-03],\n",
       "          [ 6.4701e-02,  2.9965e-02,  3.0448e-02,  ...,  2.9966e-02,\n",
       "            2.9566e-02,  2.3809e-02],\n",
       "          [ 6.6432e-02,  2.9172e-02,  2.9715e-02,  ...,  3.4490e-02,\n",
       "            3.4187e-02,  2.6304e-02],\n",
       "          ...,\n",
       "          [ 1.0680e-02,  3.6170e-02,  3.3529e-02,  ...,  3.1931e-02,\n",
       "            3.6458e-02,  3.6417e-02],\n",
       "          [ 8.7259e-03,  3.3329e-02,  3.1762e-02,  ...,  2.8712e-02,\n",
       "            3.6892e-02,  4.3257e-02],\n",
       "          [ 1.1058e-02,  2.3416e-02,  2.6858e-02,  ...,  2.2996e-02,\n",
       "            2.2338e-02,  3.1640e-02]],\n",
       "\n",
       "         [[ 2.1416e-02,  3.3011e-02,  3.5692e-02,  ...,  3.5352e-02,\n",
       "            3.5755e-02,  5.4301e-02],\n",
       "          [ 2.6360e-02,  3.4047e-02,  3.6048e-02,  ...,  3.5013e-02,\n",
       "            3.5034e-02,  4.3075e-02],\n",
       "          [ 2.7498e-02,  3.5382e-02,  3.6676e-02,  ...,  2.7005e-02,\n",
       "            3.0913e-02,  4.3417e-02],\n",
       "          ...,\n",
       "          [ 4.4420e-02,  3.8278e-02,  3.4705e-02,  ...,  3.9860e-02,\n",
       "            3.6197e-02,  3.7760e-02],\n",
       "          [ 4.4174e-02,  4.0532e-02,  4.4020e-02,  ...,  3.9264e-02,\n",
       "            3.3195e-02,  2.6996e-02],\n",
       "          [ 5.2725e-02,  5.5503e-02,  4.9490e-02,  ...,  5.3776e-02,\n",
       "            5.6882e-02,  4.7025e-02]],\n",
       "\n",
       "         [[ 2.5191e-01,  2.6223e-01,  2.6589e-01,  ...,  2.3928e-01,\n",
       "            2.3807e-01,  2.1659e-01],\n",
       "          [ 2.7205e-01,  2.8774e-01,  2.8868e-01,  ...,  2.4711e-01,\n",
       "            2.4537e-01,  2.2325e-01],\n",
       "          [ 2.7050e-01,  2.8633e-01,  2.8693e-01,  ...,  2.4144e-01,\n",
       "            2.4507e-01,  2.2217e-01],\n",
       "          ...,\n",
       "          [ 2.1401e-01,  2.3935e-01,  2.4381e-01,  ...,  2.3500e-01,\n",
       "            2.4353e-01,  2.1720e-01],\n",
       "          [ 2.0845e-01,  2.3241e-01,  2.3362e-01,  ...,  2.2744e-01,\n",
       "            2.3395e-01,  2.1398e-01],\n",
       "          [ 1.8881e-01,  1.9735e-01,  1.9692e-01,  ...,  1.8950e-01,\n",
       "            1.9009e-01,  1.8343e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.3161e-01,  1.4934e-01,  1.5555e-01,  ...,  1.4818e-01,\n",
       "            1.5083e-01,  1.3663e-01],\n",
       "          [ 1.0265e-01,  1.0758e-01,  1.1010e-01,  ...,  1.1655e-01,\n",
       "            1.1704e-01,  1.1042e-01],\n",
       "          [ 9.1108e-02,  9.0952e-02,  9.0868e-02,  ...,  8.3131e-02,\n",
       "            9.6007e-02,  9.8285e-02],\n",
       "          ...,\n",
       "          [ 1.0200e-01,  1.1379e-01,  1.2364e-01,  ...,  8.6388e-02,\n",
       "            9.6272e-02,  1.0209e-01],\n",
       "          [ 9.8931e-02,  1.1101e-01,  1.2584e-01,  ...,  9.5154e-02,\n",
       "            1.0441e-01,  1.0620e-01],\n",
       "          [ 7.3709e-02,  6.2248e-02,  6.4174e-02,  ...,  6.4449e-02,\n",
       "            6.2536e-02,  7.0114e-02]],\n",
       "\n",
       "         [[ 5.8208e-02,  5.1010e-02,  4.9022e-02,  ...,  2.8684e-02,\n",
       "            3.3402e-02,  3.2570e-02],\n",
       "          [ 4.9586e-02,  5.0393e-02,  4.3515e-02,  ...,  6.6930e-02,\n",
       "            6.0510e-02,  5.0683e-02],\n",
       "          [ 1.9743e-02,  2.4953e-02,  3.6201e-02,  ...,  2.7328e-02,\n",
       "            3.6010e-02,  4.2414e-02],\n",
       "          ...,\n",
       "          [ 3.3199e-02,  3.5722e-02,  4.8173e-02,  ...,  3.6864e-02,\n",
       "            4.1779e-02,  3.7430e-02],\n",
       "          [ 4.3533e-02,  5.7634e-02,  5.8586e-02,  ...,  4.0472e-02,\n",
       "            5.5047e-02,  6.0722e-02],\n",
       "          [ 8.1555e-02,  5.4914e-02,  5.0622e-02,  ...,  5.7652e-02,\n",
       "            5.0794e-02,  2.1315e-02]],\n",
       "\n",
       "         [[ 1.4410e-02,  3.3305e-02,  3.3939e-02,  ...,  2.9734e-02,\n",
       "            2.8348e-02,  1.4274e-01],\n",
       "          [ 1.9233e-02,  3.3061e-02,  2.8474e-02,  ...,  3.1343e-02,\n",
       "            3.4264e-02,  1.5092e-01],\n",
       "          [ 1.9112e-02,  2.7906e-02,  3.0549e-02,  ...,  3.4327e-02,\n",
       "            3.2813e-02,  1.5291e-01],\n",
       "          ...,\n",
       "          [ 2.2641e-02,  4.5303e-02,  3.1265e-02,  ...,  2.8758e-02,\n",
       "            3.1857e-02,  1.1224e-01],\n",
       "          [ 2.3025e-02,  3.2775e-02,  3.0470e-02,  ...,  2.2853e-02,\n",
       "            2.7231e-02,  1.4122e-01],\n",
       "          [ 2.9979e-02,  3.3510e-02,  3.4795e-02,  ...,  2.8921e-02,\n",
       "            2.4698e-02,  9.9320e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.4604e-02,  5.7199e-02,  5.3590e-02,  ...,  4.6159e-02,\n",
       "            4.5492e-02,  6.3448e-02],\n",
       "          [-4.4187e-02,  2.7042e-02,  3.3811e-02,  ...,  3.5993e-02,\n",
       "            3.2934e-02,  3.8063e-02],\n",
       "          [-3.4257e-02,  2.6536e-02,  2.5675e-02,  ...,  1.2508e-02,\n",
       "            4.0209e-02,  3.4112e-02],\n",
       "          ...,\n",
       "          [-4.6598e-02,  4.3365e-02,  8.4127e-02,  ...,  2.4059e-02,\n",
       "            3.8435e-02,  4.6620e-02],\n",
       "          [-2.6934e-02,  2.4443e-02,  4.2160e-02,  ...,  2.9899e-02,\n",
       "            2.3979e-02,  4.2775e-02],\n",
       "          [-3.4673e-02,  6.4695e-03, -1.8723e-03,  ...,  1.5581e-02,\n",
       "            2.2267e-03,  9.0486e-03]],\n",
       "\n",
       "         [[ 7.2967e-02,  4.9285e-02,  4.5034e-02,  ...,  4.9390e-02,\n",
       "            4.9471e-02,  2.1768e-02],\n",
       "          [ 6.7116e-02,  5.2280e-02,  4.4265e-02,  ...,  3.1811e-02,\n",
       "            3.5376e-02,  2.9088e-02],\n",
       "          [ 5.6556e-02,  5.5785e-02,  5.2725e-02,  ...,  6.4814e-02,\n",
       "            4.3571e-02,  3.4132e-02],\n",
       "          ...,\n",
       "          [ 7.1385e-02,  4.8750e-02,  3.8350e-03,  ...,  5.4425e-02,\n",
       "            4.1645e-02,  2.1675e-02],\n",
       "          [ 4.5151e-02,  4.6176e-02,  4.0785e-02,  ...,  3.7904e-02,\n",
       "            4.3060e-02,  2.8193e-02],\n",
       "          [ 9.4630e-02,  1.0087e-01,  1.0829e-01,  ...,  8.7674e-02,\n",
       "            9.5337e-02,  7.9764e-02]],\n",
       "\n",
       "         [[ 2.7476e-01,  3.1061e-01,  2.9745e-01,  ...,  1.6577e-01,\n",
       "            2.0181e-01,  2.2097e-01],\n",
       "          [ 2.8914e-01,  3.4771e-01,  3.5225e-01,  ...,  2.3001e-01,\n",
       "            2.7916e-01,  2.7098e-01],\n",
       "          [ 2.2804e-01,  2.7928e-01,  3.0298e-01,  ...,  2.6932e-01,\n",
       "            3.3997e-01,  3.0296e-01],\n",
       "          ...,\n",
       "          [ 1.8679e-01,  1.5127e-01,  9.7630e-02,  ...,  5.5005e-02,\n",
       "            6.2381e-02,  1.1764e-01],\n",
       "          [ 1.9385e-01,  2.2413e-01,  1.9969e-01,  ...,  4.6977e-02,\n",
       "            1.2115e-01,  1.8274e-01],\n",
       "          [ 2.0636e-01,  2.4519e-01,  2.5695e-01,  ...,  9.3150e-02,\n",
       "            1.7903e-01,  2.1459e-01]]]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[:2](X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.9379e-02,  7.1383e-02,  6.8835e-02,  ...,  7.3523e-02,\n",
       "            7.4663e-02,  8.0896e-02],\n",
       "          [ 8.7760e-02,  8.4119e-02,  8.3099e-02,  ...,  8.5306e-02,\n",
       "            8.4128e-02,  8.7573e-02],\n",
       "          [ 9.0997e-02,  8.9074e-02,  8.9966e-02,  ...,  9.3295e-02,\n",
       "            8.9264e-02,  8.9927e-02],\n",
       "          ...,\n",
       "          [ 1.0251e-01,  1.1618e-01,  1.2741e-01,  ...,  6.0238e-02,\n",
       "            6.1609e-02,  7.0405e-02],\n",
       "          [ 1.1096e-01,  1.2191e-01,  1.3123e-01,  ...,  7.8494e-02,\n",
       "            8.6942e-02,  9.2082e-02],\n",
       "          [ 1.0686e-01,  9.8975e-02,  8.4568e-02,  ...,  1.2511e-01,\n",
       "            1.2446e-01,  1.1611e-01]],\n",
       "\n",
       "         [[ 3.5888e-02,  3.7583e-02,  3.7414e-02,  ...,  3.9420e-02,\n",
       "            3.9037e-02,  4.1402e-02],\n",
       "          [ 3.9997e-02,  3.8029e-02,  3.8449e-02,  ...,  3.8528e-02,\n",
       "            3.8738e-02,  3.8797e-02],\n",
       "          [ 3.9698e-02,  3.8177e-02,  3.8644e-02,  ...,  4.1006e-02,\n",
       "            3.8224e-02,  3.8121e-02],\n",
       "          ...,\n",
       "          [ 2.3574e-02,  3.4700e-02,  7.5574e-02,  ...,  2.0319e-02,\n",
       "            4.0508e-02,  3.4965e-02],\n",
       "          [ 7.7698e-02,  8.3264e-02,  5.3708e-02,  ...,  4.0502e-02,\n",
       "            3.8696e-02,  3.7520e-02],\n",
       "          [ 3.0404e-02,  2.6509e-02,  2.7093e-02,  ...,  3.6524e-02,\n",
       "            3.7088e-02,  4.9994e-02]],\n",
       "\n",
       "         [[ 4.0891e-02,  3.5189e-02,  3.4012e-02,  ...,  3.3638e-02,\n",
       "            3.2703e-02,  6.4614e-03],\n",
       "          [ 3.9158e-02,  3.5539e-02,  3.4607e-02,  ...,  3.4854e-02,\n",
       "            3.3693e-02,  1.6700e-03],\n",
       "          [ 3.9493e-02,  3.6196e-02,  3.5006e-02,  ...,  3.4312e-02,\n",
       "            3.3946e-02, -3.4805e-03],\n",
       "          ...,\n",
       "          [ 5.1709e-02,  3.7210e-02,  2.6495e-02,  ...,  3.2726e-02,\n",
       "            3.2536e-02, -1.4863e-02],\n",
       "          [ 3.9978e-02,  3.4631e-02,  3.6656e-02,  ...,  3.4328e-02,\n",
       "            3.3352e-02, -1.8444e-02],\n",
       "          [ 2.8548e-02,  3.4555e-02,  3.3958e-02,  ...,  3.3722e-02,\n",
       "            3.2224e-02,  9.2310e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.5609e-02,  1.9481e-02,  2.2128e-02,  ...,  2.1607e-02,\n",
       "            2.2869e-02,  2.0490e-02],\n",
       "          [ 5.7939e-02,  2.7059e-02,  2.8362e-02,  ...,  2.3847e-02,\n",
       "            2.6112e-02,  2.5059e-02],\n",
       "          [ 6.0947e-02,  2.5871e-02,  2.6840e-02,  ...,  3.2286e-02,\n",
       "            2.4442e-02,  2.4459e-02],\n",
       "          ...,\n",
       "          [ 8.2190e-02,  1.5245e-02,  3.6233e-02,  ...,  3.1245e-02,\n",
       "            2.4123e-02,  1.6402e-02],\n",
       "          [ 7.0674e-02, -3.0480e-03,  3.5105e-03,  ...,  2.5777e-02,\n",
       "            3.1268e-02,  2.7707e-02],\n",
       "          [ 6.7160e-02,  1.7566e-02, -4.3820e-03,  ...,  4.1886e-02,\n",
       "            4.2271e-02,  4.4348e-02]],\n",
       "\n",
       "         [[ 2.6397e-02,  3.6549e-02,  3.8616e-02,  ...,  4.1038e-02,\n",
       "            4.0269e-02,  4.5602e-02],\n",
       "          [ 2.9745e-02,  3.7350e-02,  3.8869e-02,  ...,  4.1130e-02,\n",
       "            4.0984e-02,  4.2907e-02],\n",
       "          [ 3.0774e-02,  3.8832e-02,  3.9453e-02,  ...,  3.1426e-02,\n",
       "            4.1065e-02,  4.4159e-02],\n",
       "          ...,\n",
       "          [ 1.7222e-02,  1.8524e-02, -1.0051e-02,  ...,  4.4256e-02,\n",
       "            3.6202e-02,  4.6458e-02],\n",
       "          [ 3.7121e-02,  6.0694e-02,  6.8508e-02,  ...,  3.6621e-02,\n",
       "            3.4304e-02,  4.0221e-02],\n",
       "          [ 1.7055e-02,  3.0601e-02,  5.9315e-02,  ...,  2.7397e-03,\n",
       "            4.4241e-03,  1.3524e-02]],\n",
       "\n",
       "         [[ 1.9805e-01,  2.0243e-01,  2.0582e-01,  ...,  2.1381e-01,\n",
       "            2.1436e-01,  1.9740e-01],\n",
       "          [ 2.0108e-01,  2.0592e-01,  2.1160e-01,  ...,  2.2325e-01,\n",
       "            2.2592e-01,  2.0390e-01],\n",
       "          [ 1.9316e-01,  1.9642e-01,  2.0154e-01,  ...,  2.0799e-01,\n",
       "            2.1801e-01,  1.9939e-01],\n",
       "          ...,\n",
       "          [ 1.7332e-01,  1.6895e-01,  1.7905e-01,  ...,  1.4535e-01,\n",
       "            1.5263e-01,  1.6596e-01],\n",
       "          [ 1.7833e-01,  1.7061e-01,  1.7305e-01,  ...,  1.3851e-01,\n",
       "            1.4328e-01,  1.6419e-01],\n",
       "          [ 1.8649e-01,  1.7950e-01,  1.8215e-01,  ...,  1.6612e-01,\n",
       "            1.6825e-01,  1.7788e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.7624e-02,  8.2542e-02,  7.9438e-02,  ...,  9.5423e-02,\n",
       "            1.0033e-01,  1.0132e-01],\n",
       "          [ 9.3371e-02,  9.2600e-02,  9.2641e-02,  ...,  1.0486e-01,\n",
       "            1.0426e-01,  1.0181e-01],\n",
       "          [ 9.7207e-02,  9.8762e-02,  1.0003e-01,  ...,  1.0576e-01,\n",
       "            1.0447e-01,  1.0117e-01],\n",
       "          ...,\n",
       "          [ 9.7192e-02,  9.7736e-02,  9.5234e-02,  ...,  9.1437e-02,\n",
       "            9.2747e-02,  9.4099e-02],\n",
       "          [ 9.6045e-02,  9.6232e-02,  9.6151e-02,  ...,  9.5724e-02,\n",
       "            9.6858e-02,  9.6899e-02],\n",
       "          [ 8.0088e-02,  7.2684e-02,  7.0601e-02,  ...,  7.2372e-02,\n",
       "            7.1850e-02,  7.7967e-02]],\n",
       "\n",
       "         [[ 3.6276e-02,  3.6905e-02,  3.8085e-02,  ...,  5.0296e-02,\n",
       "            4.6908e-02,  3.8760e-02],\n",
       "          [ 4.0092e-02,  3.9504e-02,  4.0124e-02,  ...,  3.9478e-02,\n",
       "            4.2820e-02,  4.7285e-02],\n",
       "          [ 4.0125e-02,  3.9471e-02,  4.0062e-02,  ...,  4.3425e-02,\n",
       "            3.8416e-02,  4.2272e-02],\n",
       "          ...,\n",
       "          [ 4.0821e-02,  4.3731e-02,  4.4480e-02,  ...,  4.0284e-02,\n",
       "            4.1414e-02,  4.2058e-02],\n",
       "          [ 4.1752e-02,  4.1215e-02,  4.1469e-02,  ...,  4.0244e-02,\n",
       "            4.0107e-02,  4.1170e-02],\n",
       "          [ 5.5565e-02,  4.5031e-02,  4.2993e-02,  ...,  4.7297e-02,\n",
       "            4.6143e-02,  3.3506e-02]],\n",
       "\n",
       "         [[ 3.6707e-02,  3.3925e-02,  3.3698e-02,  ...,  3.3865e-02,\n",
       "            4.0065e-02,  4.4239e-02],\n",
       "          [ 3.6574e-02,  3.4528e-02,  3.4871e-02,  ...,  2.5268e-02,\n",
       "            3.1242e-02,  4.2160e-02],\n",
       "          [ 3.5852e-02,  3.4910e-02,  3.5199e-02,  ...,  1.5490e-02,\n",
       "            3.5204e-02,  5.0683e-02],\n",
       "          ...,\n",
       "          [ 3.0006e-02,  3.4209e-02,  3.2439e-02,  ...,  3.3220e-02,\n",
       "            3.3835e-02,  8.0542e-02],\n",
       "          [ 3.0725e-02,  3.2219e-02,  3.1640e-02,  ...,  3.3450e-02,\n",
       "            3.2968e-02,  8.3995e-02],\n",
       "          [ 3.3958e-02,  3.3466e-02,  3.3612e-02,  ...,  3.3810e-02,\n",
       "            3.3862e-02,  6.7460e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7835e-02,  3.0103e-02,  2.8596e-02,  ...,  2.2575e-02,\n",
       "            2.6052e-02,  3.6716e-02],\n",
       "          [ 4.1377e-02,  3.4733e-02,  3.4204e-02,  ...,  2.7699e-02,\n",
       "            2.2869e-02,  3.9469e-02],\n",
       "          [ 4.0878e-02,  3.4485e-02,  3.3719e-02,  ...,  3.2549e-02,\n",
       "            1.9326e-02,  4.1262e-02],\n",
       "          ...,\n",
       "          [-5.1181e-03,  3.2970e-02,  3.8059e-02,  ...,  3.2194e-02,\n",
       "            3.2806e-02,  3.2746e-02],\n",
       "          [-5.1646e-03,  3.3940e-02,  3.4525e-02,  ...,  3.2255e-02,\n",
       "            3.2455e-02,  3.2581e-02],\n",
       "          [-6.8591e-03,  1.7512e-02,  2.1620e-02,  ...,  2.0895e-02,\n",
       "            2.1460e-02,  1.8358e-02]],\n",
       "\n",
       "         [[ 3.0764e-02,  3.2779e-02,  3.3892e-02,  ...,  3.8131e-02,\n",
       "            3.8351e-02,  3.5287e-02],\n",
       "          [ 3.4116e-02,  3.5074e-02,  3.4975e-02,  ...,  3.8802e-02,\n",
       "            3.8421e-02,  3.0851e-02],\n",
       "          [ 3.3908e-02,  3.4582e-02,  3.4812e-02,  ...,  3.6358e-02,\n",
       "            3.9600e-02,  3.1853e-02],\n",
       "          ...,\n",
       "          [ 4.9174e-02,  4.1691e-02,  3.8520e-02,  ...,  4.2401e-02,\n",
       "            4.0820e-02,  3.5682e-02],\n",
       "          [ 4.9204e-02,  4.1335e-02,  3.9710e-02,  ...,  4.0304e-02,\n",
       "            4.1013e-02,  3.5896e-02],\n",
       "          [ 6.7940e-02,  7.2471e-02,  7.0403e-02,  ...,  6.8981e-02,\n",
       "            6.9409e-02,  6.2103e-02]],\n",
       "\n",
       "         [[ 2.1453e-01,  2.2572e-01,  2.2853e-01,  ...,  2.2061e-01,\n",
       "            2.1507e-01,  1.9942e-01],\n",
       "          [ 2.2780e-01,  2.4375e-01,  2.4637e-01,  ...,  2.3501e-01,\n",
       "            2.2939e-01,  2.0753e-01],\n",
       "          [ 2.2811e-01,  2.4349e-01,  2.4426e-01,  ...,  2.3119e-01,\n",
       "            2.2639e-01,  2.0480e-01],\n",
       "          ...,\n",
       "          [ 1.8580e-01,  2.0105e-01,  2.0134e-01,  ...,  1.9593e-01,\n",
       "            1.9453e-01,  1.9072e-01],\n",
       "          [ 1.9138e-01,  2.0128e-01,  1.9949e-01,  ...,  1.9695e-01,\n",
       "            1.9637e-01,  1.9133e-01],\n",
       "          [ 1.8654e-01,  1.9221e-01,  1.9084e-01,  ...,  1.8803e-01,\n",
       "            1.8800e-01,  1.8495e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2323e-01,  1.3325e-01,  1.2870e-01,  ...,  1.4197e-01,\n",
       "            1.4204e-01,  1.2914e-01],\n",
       "          [ 1.0423e-01,  1.0662e-01,  1.0333e-01,  ...,  1.0961e-01,\n",
       "            1.0970e-01,  1.0572e-01],\n",
       "          [ 9.5728e-02,  9.7120e-02,  9.6196e-02,  ...,  9.5948e-02,\n",
       "            9.5886e-02,  9.5834e-02],\n",
       "          ...,\n",
       "          [ 9.5628e-02,  9.5518e-02,  9.4301e-02,  ...,  8.5187e-02,\n",
       "            9.1830e-02,  9.5851e-02],\n",
       "          [ 9.5786e-02,  9.5249e-02,  8.9160e-02,  ...,  7.8573e-02,\n",
       "            8.5487e-02,  9.3673e-02],\n",
       "          [ 7.4201e-02,  6.3107e-02,  5.8806e-02,  ...,  6.4864e-02,\n",
       "            5.9909e-02,  6.8253e-02]],\n",
       "\n",
       "         [[ 5.1542e-02,  4.3375e-02,  3.6287e-02,  ...,  4.5219e-02,\n",
       "            4.5234e-02,  3.6799e-02],\n",
       "          [ 4.1138e-02,  4.1825e-02,  4.1138e-02,  ...,  4.2699e-02,\n",
       "            4.2730e-02,  4.3129e-02],\n",
       "          [ 4.1574e-02,  4.0758e-02,  4.1474e-02,  ...,  4.2479e-02,\n",
       "            4.2436e-02,  4.2155e-02],\n",
       "          ...,\n",
       "          [ 4.1536e-02,  4.2372e-02,  4.2062e-02,  ...,  4.0458e-02,\n",
       "            4.0929e-02,  4.2104e-02],\n",
       "          [ 4.1585e-02,  4.2787e-02,  4.6014e-02,  ...,  3.7614e-02,\n",
       "            3.9300e-02,  4.1231e-02],\n",
       "          [ 6.1373e-02,  4.6552e-02,  2.3557e-02,  ...,  4.6744e-02,\n",
       "            5.3106e-02,  3.0447e-02]],\n",
       "\n",
       "         [[ 2.4397e-02,  2.2546e-02,  2.6321e-02,  ...,  3.4436e-02,\n",
       "            3.4409e-02,  9.8772e-02],\n",
       "          [ 2.7738e-02,  2.0347e-02,  2.4556e-02,  ...,  3.3322e-02,\n",
       "            3.3363e-02,  1.0188e-01],\n",
       "          [ 2.7553e-02,  1.6541e-02,  3.8574e-02,  ...,  3.3392e-02,\n",
       "            3.3493e-02,  1.0265e-01],\n",
       "          ...,\n",
       "          [ 2.7778e-02,  3.2725e-02,  2.9111e-02,  ...,  3.5186e-02,\n",
       "            3.3349e-02,  1.0350e-01],\n",
       "          [ 2.8004e-02,  3.1700e-02,  3.4535e-02,  ...,  3.4219e-02,\n",
       "            3.2417e-02,  1.0321e-01],\n",
       "          [ 3.2745e-02,  3.0935e-02,  3.9674e-02,  ...,  2.6497e-02,\n",
       "            3.3016e-02,  7.8129e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1083e-04,  5.1366e-02,  6.0980e-02,  ...,  4.6848e-02,\n",
       "            4.7185e-02,  5.7968e-02],\n",
       "          [-2.0324e-02,  3.1863e-02,  5.2149e-02,  ...,  3.2357e-02,\n",
       "            3.2851e-02,  3.7226e-02],\n",
       "          [-1.8904e-02,  3.0553e-02,  5.1085e-02,  ...,  3.3479e-02,\n",
       "            3.3966e-02,  3.3901e-02],\n",
       "          ...,\n",
       "          [-1.8463e-02,  3.3053e-02,  3.3876e-02,  ...,  1.5883e-02,\n",
       "            3.2845e-02,  3.3697e-02],\n",
       "          [-1.8507e-02,  3.3238e-02,  3.5618e-02,  ...,  2.9999e-03,\n",
       "            1.5597e-02,  3.5242e-02],\n",
       "          [-1.9339e-02,  1.0329e-02,  2.0929e-02,  ...,  1.0654e-02,\n",
       "           -8.1651e-03,  1.0587e-02]],\n",
       "\n",
       "         [[ 6.3560e-02,  4.1949e-02,  3.1727e-02,  ...,  4.2803e-02,\n",
       "            4.2712e-02,  2.4193e-02],\n",
       "          [ 5.6074e-02,  4.3196e-02,  3.2979e-02,  ...,  4.3580e-02,\n",
       "            4.3386e-02,  3.5391e-02],\n",
       "          [ 5.3634e-02,  4.2369e-02,  3.1340e-02,  ...,  4.1970e-02,\n",
       "            4.1950e-02,  3.5308e-02],\n",
       "          ...,\n",
       "          [ 5.3374e-02,  4.3936e-02,  4.1325e-02,  ...,  5.6300e-02,\n",
       "            4.4077e-02,  3.5053e-02],\n",
       "          [ 5.3521e-02,  4.3945e-02,  4.2847e-02,  ...,  6.4351e-02,\n",
       "            5.5279e-02,  3.5325e-02],\n",
       "          [ 7.8510e-02,  8.4913e-02,  7.0351e-02,  ...,  6.7074e-02,\n",
       "            8.7695e-02,  7.5446e-02]],\n",
       "\n",
       "         [[ 1.8108e-01,  1.8266e-01,  1.7457e-01,  ...,  1.8586e-01,\n",
       "            1.8596e-01,  1.8506e-01],\n",
       "          [ 1.8308e-01,  1.8560e-01,  1.7532e-01,  ...,  1.9247e-01,\n",
       "            1.9222e-01,  1.8807e-01],\n",
       "          [ 1.8143e-01,  1.8469e-01,  1.7386e-01,  ...,  1.8966e-01,\n",
       "            1.8980e-01,  1.8715e-01],\n",
       "          ...,\n",
       "          [ 1.8120e-01,  1.9016e-01,  1.8381e-01,  ...,  1.8392e-01,\n",
       "            1.9014e-01,  1.8889e-01],\n",
       "          [ 1.8101e-01,  1.8979e-01,  1.7826e-01,  ...,  1.7574e-01,\n",
       "            1.8405e-01,  1.8844e-01],\n",
       "          [ 1.7804e-01,  1.8145e-01,  1.7410e-01,  ...,  1.7505e-01,\n",
       "            1.7681e-01,  1.8159e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.0497e-01,  1.0762e-01,  1.0476e-01,  ...,  8.3921e-02,\n",
       "            7.9428e-02,  8.1750e-02],\n",
       "          [ 9.5414e-02,  9.8145e-02,  1.0008e-01,  ...,  1.0191e-01,\n",
       "            9.9782e-02,  9.6790e-02],\n",
       "          [ 9.5868e-02,  9.9440e-02,  1.0572e-01,  ...,  1.2064e-01,\n",
       "            1.2510e-01,  1.1828e-01],\n",
       "          ...,\n",
       "          [ 9.1075e-02,  9.0721e-02,  8.8657e-02,  ...,  9.1316e-02,\n",
       "            8.0351e-02,  7.6667e-02],\n",
       "          [ 9.2281e-02,  9.2438e-02,  9.6357e-02,  ...,  1.0630e-01,\n",
       "            1.0070e-01,  9.5843e-02],\n",
       "          [ 9.0960e-02,  8.9884e-02,  9.2366e-02,  ...,  8.2452e-02,\n",
       "            9.1959e-02,  9.7458e-02]],\n",
       "\n",
       "         [[ 4.8679e-02,  4.9737e-02,  4.7969e-02,  ..., -2.3688e-02,\n",
       "           -3.5289e-04,  4.0397e-02],\n",
       "          [ 3.2888e-02,  3.8085e-02,  4.3136e-02,  ...,  1.1077e-01,\n",
       "            7.3023e-02,  2.2158e-02],\n",
       "          [ 4.4449e-02,  3.5846e-02,  3.6840e-02,  ...,  1.3280e-02,\n",
       "            1.2958e-02,  6.5905e-02],\n",
       "          ...,\n",
       "          [ 3.2522e-02,  3.3046e-02,  3.9350e-02,  ...,  3.1969e-02,\n",
       "            1.5012e-02,  2.5395e-02],\n",
       "          [ 4.1282e-02,  4.0553e-02,  2.6576e-02,  ...,  7.0644e-02,\n",
       "            6.1112e-02,  4.4396e-02],\n",
       "          [ 4.2792e-02,  4.8131e-02,  5.5781e-02,  ...,  2.9584e-02,\n",
       "            4.0535e-02,  4.6778e-02]],\n",
       "\n",
       "         [[ 2.0993e-02,  1.3918e-02,  2.5660e-02,  ...,  3.7697e-02,\n",
       "            3.0451e-02,  2.4429e-03],\n",
       "          [ 2.9528e-02,  1.5854e-02,  3.4770e-02,  ...,  2.6196e-02,\n",
       "            2.8219e-02,  2.8556e-02],\n",
       "          [ 2.2703e-02, -7.4140e-03,  3.8855e-02,  ...,  3.8928e-02,\n",
       "            3.9727e-02,  7.6299e-02],\n",
       "          ...,\n",
       "          [ 3.0669e-02,  8.7646e-03,  2.9615e-02,  ...,  2.8922e-02,\n",
       "            3.9075e-02,  9.0730e-02],\n",
       "          [ 4.0549e-02,  1.5617e-02,  4.4564e-02,  ...,  3.4502e-02,\n",
       "            5.5571e-02,  6.8298e-02],\n",
       "          [ 3.7614e-02,  2.9805e-02,  4.1324e-02,  ...,  3.6774e-02,\n",
       "            3.2230e-02,  5.0090e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7417e-02,  4.3935e-02,  4.9082e-02,  ...,  3.2007e-02,\n",
       "            4.1926e-02,  1.9582e-02],\n",
       "          [ 1.0457e-02,  3.2051e-02,  3.7928e-02,  ...,  4.9855e-02,\n",
       "            5.2075e-02,  3.4797e-02],\n",
       "          [ 1.3753e-02,  4.1794e-02,  2.6677e-02,  ...,  6.0804e-02,\n",
       "            5.8986e-02,  4.4382e-02],\n",
       "          ...,\n",
       "          [ 9.3363e-03,  3.6840e-02,  3.2284e-02,  ...,  8.6587e-02,\n",
       "            7.2118e-03, -1.8179e-02],\n",
       "          [ 1.4987e-02,  4.2500e-02,  3.0090e-02,  ...,  6.9538e-02,\n",
       "            7.4765e-02,  1.8142e-02],\n",
       "          [ 1.5193e-02,  3.2221e-02,  2.8839e-02,  ...,  2.3700e-02,\n",
       "            3.5142e-02,  3.5073e-02]],\n",
       "\n",
       "         [[ 5.1483e-02,  3.8203e-02,  2.5891e-02,  ...,  5.5685e-02,\n",
       "            4.1716e-02,  4.8451e-02],\n",
       "          [ 4.4509e-02,  4.2937e-02,  3.5957e-02,  ..., -5.1938e-04,\n",
       "            1.0948e-02,  2.5344e-02],\n",
       "          [ 3.6336e-02,  3.4934e-02,  3.6942e-02,  ...,  2.5926e-02,\n",
       "            2.4137e-02,  1.8227e-02],\n",
       "          ...,\n",
       "          [ 4.6884e-02,  4.5537e-02,  4.3471e-02,  ..., -1.9776e-02,\n",
       "            5.1757e-02,  8.3064e-02],\n",
       "          [ 3.8097e-02,  3.2115e-02,  3.2818e-02,  ...,  3.8259e-02,\n",
       "           -1.3062e-02,  1.1295e-02],\n",
       "          [ 5.1913e-02,  5.2517e-02,  5.0543e-02,  ...,  6.0596e-02,\n",
       "            7.0522e-02,  5.1026e-02]],\n",
       "\n",
       "         [[ 1.6948e-01,  1.6367e-01,  1.5658e-01,  ...,  1.1846e-01,\n",
       "            7.8074e-02,  9.2194e-02],\n",
       "          [ 1.7870e-01,  1.7481e-01,  1.7459e-01,  ...,  8.9406e-02,\n",
       "            4.4520e-02,  6.8520e-02],\n",
       "          [ 1.7803e-01,  1.7489e-01,  1.8249e-01,  ...,  1.1699e-01,\n",
       "            8.9652e-02,  1.2355e-01],\n",
       "          ...,\n",
       "          [ 1.4000e-01,  1.2691e-01,  1.2495e-01,  ...,  1.2969e-01,\n",
       "            1.3061e-01,  1.5652e-01],\n",
       "          [ 1.1107e-01,  1.0111e-01,  1.1586e-01,  ...,  1.3011e-01,\n",
       "            1.1355e-01,  1.3836e-01],\n",
       "          [ 1.2502e-01,  1.1937e-01,  1.3611e-01,  ...,  1.2731e-01,\n",
       "            1.0550e-01,  1.3375e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.2004e-02,  7.4867e-02,  7.1938e-02,  ...,  6.4188e-02,\n",
       "            6.3512e-02,  7.2122e-02],\n",
       "          [ 8.9886e-02,  8.7099e-02,  8.6097e-02,  ...,  8.3448e-02,\n",
       "            8.3195e-02,  8.6466e-02],\n",
       "          [ 9.3581e-02,  9.2811e-02,  9.2516e-02,  ...,  9.5813e-02,\n",
       "            9.5437e-02,  9.3365e-02],\n",
       "          ...,\n",
       "          [ 9.5929e-02,  9.5631e-02,  9.5993e-02,  ...,  9.7299e-02,\n",
       "            9.8021e-02,  9.7424e-02],\n",
       "          [ 9.4829e-02,  9.5381e-02,  9.6793e-02,  ...,  9.7352e-02,\n",
       "            9.8347e-02,  9.8188e-02],\n",
       "          [ 8.9795e-02,  8.7460e-02,  8.6998e-02,  ...,  8.9439e-02,\n",
       "            9.0376e-02,  9.2653e-02]],\n",
       "\n",
       "         [[ 3.5137e-02,  3.6609e-02,  3.7269e-02,  ...,  3.6238e-02,\n",
       "            3.5835e-02,  4.1195e-02],\n",
       "          [ 4.0169e-02,  3.8675e-02,  3.8635e-02,  ...,  3.7177e-02,\n",
       "            3.7602e-02,  3.7684e-02],\n",
       "          [ 3.9525e-02,  3.8460e-02,  3.8589e-02,  ...,  3.7875e-02,\n",
       "            4.0136e-02,  3.8567e-02],\n",
       "          ...,\n",
       "          [ 4.1619e-02,  4.3727e-02,  4.1327e-02,  ...,  3.7759e-02,\n",
       "            3.6720e-02,  3.4697e-02],\n",
       "          [ 4.1893e-02,  3.8631e-02,  3.9829e-02,  ...,  4.6376e-02,\n",
       "            4.6207e-02,  4.4399e-02],\n",
       "          [ 4.2718e-02,  4.6676e-02,  4.1951e-02,  ...,  3.9454e-02,\n",
       "            4.3820e-02,  3.8362e-02]],\n",
       "\n",
       "         [[ 3.9285e-02,  3.4702e-02,  3.4015e-02,  ...,  3.3875e-02,\n",
       "            3.3623e-02, -1.0962e-02],\n",
       "          [ 3.8195e-02,  3.5007e-02,  3.4975e-02,  ...,  3.4494e-02,\n",
       "            3.4671e-02, -1.4825e-02],\n",
       "          [ 3.8410e-02,  3.5251e-02,  3.5145e-02,  ...,  2.9469e-02,\n",
       "            3.4970e-02, -1.7519e-02],\n",
       "          ...,\n",
       "          [ 3.4015e-02,  3.5968e-02,  3.7041e-02,  ...,  3.2040e-02,\n",
       "            3.3950e-02,  3.8585e-02],\n",
       "          [ 3.5528e-02,  3.4417e-02,  3.6093e-02,  ...,  3.4954e-02,\n",
       "            4.0088e-02,  4.2032e-02],\n",
       "          [ 3.5104e-02,  3.5843e-02,  3.6798e-02,  ...,  3.2825e-02,\n",
       "            3.5363e-02,  3.9438e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.3727e-02,  2.3055e-02,  2.4257e-02,  ...,  2.1465e-02,\n",
       "            2.1104e-02,  1.3552e-02],\n",
       "          [ 5.3214e-02,  3.0389e-02,  3.0706e-02,  ...,  3.0389e-02,\n",
       "            3.0127e-02,  2.6344e-02],\n",
       "          [ 5.4351e-02,  2.9868e-02,  3.0225e-02,  ...,  3.3362e-02,\n",
       "            3.3163e-02,  2.7983e-02],\n",
       "          ...,\n",
       "          [ 1.7717e-02,  3.4466e-02,  3.2731e-02,  ...,  3.1680e-02,\n",
       "            3.4655e-02,  3.4628e-02],\n",
       "          [ 1.6433e-02,  3.2599e-02,  3.1570e-02,  ...,  2.9566e-02,\n",
       "            3.4940e-02,  3.9123e-02],\n",
       "          [ 1.7965e-02,  2.6086e-02,  2.8347e-02,  ...,  2.5810e-02,\n",
       "            2.5377e-02,  3.1489e-02]],\n",
       "\n",
       "         [[ 2.7468e-02,  3.5201e-02,  3.6988e-02,  ...,  3.6762e-02,\n",
       "            3.7031e-02,  4.9399e-02],\n",
       "          [ 3.0765e-02,  3.5891e-02,  3.7226e-02,  ...,  3.6536e-02,\n",
       "            3.6550e-02,  4.1913e-02],\n",
       "          [ 3.1524e-02,  3.6782e-02,  3.7645e-02,  ...,  3.1195e-02,\n",
       "            3.3802e-02,  4.2141e-02],\n",
       "          ...,\n",
       "          [ 4.2810e-02,  3.8713e-02,  3.6330e-02,  ...,  3.9769e-02,\n",
       "            3.7326e-02,  3.8368e-02],\n",
       "          [ 4.2646e-02,  4.0217e-02,  4.2543e-02,  ...,  3.9371e-02,\n",
       "            3.5323e-02,  3.1189e-02],\n",
       "          [ 4.8348e-02,  5.0201e-02,  4.6191e-02,  ...,  4.9049e-02,\n",
       "            5.1120e-02,  4.4547e-02]],\n",
       "\n",
       "         [[ 2.0034e-01,  2.0393e-01,  2.0520e-01,  ...,  1.9594e-01,\n",
       "            1.9552e-01,  1.8805e-01],\n",
       "          [ 2.0734e-01,  2.1280e-01,  2.1313e-01,  ...,  1.9867e-01,\n",
       "            1.9806e-01,  1.9037e-01],\n",
       "          [ 2.0680e-01,  2.1231e-01,  2.1252e-01,  ...,  1.9669e-01,\n",
       "            1.9796e-01,  1.8999e-01],\n",
       "          ...,\n",
       "          [ 1.8715e-01,  1.9597e-01,  1.9752e-01,  ...,  1.9445e-01,\n",
       "            1.9742e-01,  1.8827e-01],\n",
       "          [ 1.8522e-01,  1.9356e-01,  1.9398e-01,  ...,  1.9182e-01,\n",
       "            1.9409e-01,  1.8714e-01],\n",
       "          [ 1.7839e-01,  1.8136e-01,  1.8121e-01,  ...,  1.7863e-01,\n",
       "            1.7883e-01,  1.7652e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2117e-01,  1.3361e-01,  1.3797e-01,  ...,  1.3280e-01,\n",
       "            1.3466e-01,  1.2469e-01],\n",
       "          [ 1.0084e-01,  1.0430e-01,  1.0607e-01,  ...,  1.1059e-01,\n",
       "            1.1094e-01,  1.0629e-01],\n",
       "          [ 9.2731e-02,  9.2621e-02,  9.2562e-02,  ...,  8.7130e-02,\n",
       "            9.6170e-02,  9.7769e-02],\n",
       "          ...,\n",
       "          [ 1.0037e-01,  1.0865e-01,  1.1557e-01,  ...,  8.9417e-02,\n",
       "            9.6356e-02,  1.0044e-01],\n",
       "          [ 9.8223e-02,  1.0670e-01,  1.1711e-01,  ...,  9.5571e-02,\n",
       "            1.0207e-01,  1.0333e-01],\n",
       "          [ 8.0515e-02,  7.2469e-02,  7.3821e-02,  ...,  7.4014e-02,\n",
       "            7.2670e-02,  7.7991e-02]],\n",
       "\n",
       "         [[ 5.0590e-02,  4.6558e-02,  4.5444e-02,  ...,  3.4050e-02,\n",
       "            3.6693e-02,  3.6227e-02],\n",
       "          [ 4.5760e-02,  4.6212e-02,  4.2359e-02,  ...,  5.5476e-02,\n",
       "            5.1880e-02,  4.6374e-02],\n",
       "          [ 2.9041e-02,  3.1960e-02,  3.8261e-02,  ...,  3.3290e-02,\n",
       "            3.8154e-02,  4.1742e-02],\n",
       "          ...,\n",
       "          [ 3.6580e-02,  3.7993e-02,  4.4968e-02,  ...,  3.8633e-02,\n",
       "            4.1386e-02,  3.8950e-02],\n",
       "          [ 4.2369e-02,  5.0268e-02,  5.0802e-02,  ...,  4.0654e-02,\n",
       "            4.8819e-02,  5.1999e-02],\n",
       "          [ 6.3670e-02,  4.8745e-02,  4.6340e-02,  ...,  5.0279e-02,\n",
       "            4.6437e-02,  2.9922e-02]],\n",
       "\n",
       "         [[ 2.3912e-02,  3.3985e-02,  3.4323e-02,  ...,  3.2081e-02,\n",
       "            3.1342e-02,  9.2327e-02],\n",
       "          [ 2.6483e-02,  3.3855e-02,  3.1410e-02,  ...,  3.2939e-02,\n",
       "            3.4496e-02,  9.6683e-02],\n",
       "          [ 2.6419e-02,  3.1107e-02,  3.2516e-02,  ...,  3.4530e-02,\n",
       "            3.3723e-02,  9.7744e-02],\n",
       "          ...,\n",
       "          [ 2.8300e-02,  4.0381e-02,  3.2897e-02,  ...,  3.1561e-02,\n",
       "            3.3213e-02,  7.6066e-02],\n",
       "          [ 2.8505e-02,  3.3702e-02,  3.2474e-02,  ...,  2.8413e-02,\n",
       "            3.0747e-02,  9.1514e-02],\n",
       "          [ 3.2212e-02,  3.4094e-02,  3.4779e-02,  ...,  3.1648e-02,\n",
       "            2.9396e-02,  6.9177e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1025e-03,  4.8284e-02,  4.5913e-02,  ...,  4.1030e-02,\n",
       "            4.0592e-02,  5.2390e-02],\n",
       "          [-1.8336e-02,  2.8468e-02,  3.2916e-02,  ...,  3.4350e-02,\n",
       "            3.2340e-02,  3.5710e-02],\n",
       "          [-1.1811e-02,  2.8136e-02,  2.7570e-02,  ...,  1.8918e-02,\n",
       "            3.7120e-02,  3.3114e-02],\n",
       "          ...,\n",
       "          [-1.9920e-02,  3.9194e-02,  6.5978e-02,  ...,  2.6508e-02,\n",
       "            3.5954e-02,  4.1332e-02],\n",
       "          [-6.9990e-03,  2.6760e-02,  3.8402e-02,  ...,  3.0345e-02,\n",
       "            2.6455e-02,  3.8806e-02],\n",
       "          [-1.2084e-02,  1.4950e-02,  9.4688e-03,  ...,  2.0937e-02,\n",
       "            1.2162e-02,  1.6645e-02]],\n",
       "\n",
       "         [[ 6.1848e-02,  4.6054e-02,  4.3219e-02,  ...,  4.6124e-02,\n",
       "            4.6178e-02,  2.7703e-02],\n",
       "          [ 5.7946e-02,  4.8051e-02,  4.2707e-02,  ...,  3.4401e-02,\n",
       "            3.6778e-02,  3.2584e-02],\n",
       "          [ 5.0903e-02,  5.0389e-02,  4.8349e-02,  ...,  5.6410e-02,\n",
       "            4.2243e-02,  3.5948e-02],\n",
       "          ...,\n",
       "          [ 6.0793e-02,  4.5697e-02,  1.5743e-02,  ...,  4.9482e-02,\n",
       "            4.0959e-02,  2.7640e-02],\n",
       "          [ 4.3297e-02,  4.3981e-02,  4.0385e-02,  ...,  3.8464e-02,\n",
       "            4.1903e-02,  3.1987e-02],\n",
       "          [ 7.6295e-02,  8.0460e-02,  8.5402e-02,  ...,  7.1656e-02,\n",
       "            7.6767e-02,  6.6381e-02]],\n",
       "\n",
       "         [[ 2.0829e-01,  2.2075e-01,  2.1618e-01,  ...,  1.7038e-01,\n",
       "            1.8291e-01,  1.8957e-01],\n",
       "          [ 2.1329e-01,  2.3366e-01,  2.3524e-01,  ...,  1.9272e-01,\n",
       "            2.0982e-01,  2.0697e-01],\n",
       "          [ 1.9204e-01,  2.0986e-01,  2.1810e-01,  ...,  2.0639e-01,\n",
       "            2.3097e-01,  2.1810e-01],\n",
       "          ...,\n",
       "          [ 1.7769e-01,  1.6533e-01,  1.4667e-01,  ...,  1.3185e-01,\n",
       "            1.3441e-01,  1.5363e-01],\n",
       "          [ 1.8014e-01,  1.9067e-01,  1.8217e-01,  ...,  1.2905e-01,\n",
       "            1.5485e-01,  1.7628e-01],\n",
       "          [ 1.8449e-01,  1.9800e-01,  2.0209e-01,  ...,  1.4511e-01,\n",
       "            1.7499e-01,  1.8736e-01]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Sequential(\n",
    "    model.features.conv0,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ce311d752f7559aeab697e045d55b95fb71177de97c9fd9eefeb88845310a84"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
