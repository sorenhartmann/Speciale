{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from optuna import Study\n",
    "from src.utils import Run, Sweep, set_directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = {}\n",
    "with set_directory(\"..\"):\n",
    "    optuna_storages = list(Path(\"optuna_storages/\").glob(\"mnist*\"))\n",
    "    for storage in optuna_storages:\n",
    "        if \"corr\" in storage.stem:\n",
    "            continue\n",
    "        studies[storage.stem] = Study(storage.stem, storage=f\"sqlite:///{storage}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_loss_data = (\n",
    "    pd.concat(\n",
    "        Sweep(study).loss().assign(study=name).set_index(\"study\", append=True)\n",
    "        for name, study in studies.items()\n",
    "    )\n",
    "    .reorder_levels([\"study\", \"trial\", \"step\"])\n",
    ")\n",
    "combined_summaries_data = (\n",
    "    pd.concat(\n",
    "        Sweep(study).summary().assign(study=name).set_index(\"study\", append=True)\n",
    "        for name, study in studies.items()\n",
    "    )\n",
    "    .reorder_levels([\"study\", \"trial\"])\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_runs = combined_summaries_data[\"err/val\"].groupby(\"study\").idxmin()\n",
    "best_runs.pipe(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    combined_loss_data\n",
    "    .unstack(level=\"step\")\n",
    "    .loc[best_runs]\n",
    "    .stack(level=\"step\")\n",
    "    .reset_index()\n",
    "    .pipe((sns.relplot, \"data\"), x=\"step\", y=\"err/val\", hue=\"study\", kind=\"line\", aspect=1.6)\n",
    "    .set(ylim=(0.01, 0.03))\n",
    "    .savefig(\"../thesis/Figures/mnist-best-runs-val-curves.pdf\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def rename_cols(x):\n",
    "\n",
    "    if x == \"err/val\":\n",
    "        return \"val. error\"\n",
    "    else:\n",
    "        \n",
    "        return f\"\\\\texttt{{{x.split('.')[-1]}}}\".replace(\"_\", \"\\_\")\n",
    "\n",
    "def format_sctf(float_number):\n",
    "    exponent = math.floor(math.log10(float_number))\n",
    "    mantissa = float_number / 10 ** exponent\n",
    "    mantissa_format = str(mantissa)[0:4]\n",
    "    return \"${0}\\\\times10^{{{1}}}$\".format(mantissa_format, str(int(exponent)))\n",
    "\n",
    "\n",
    "def to_latex(data: pd.DataFrame):\n",
    "\n",
    "    n_cols = len(data.columns)\n",
    "    return data.to_latex(\n",
    "        f\"../thesis/Tables/{key}-hparams.tex\",\n",
    "        escape=False,\n",
    "        formatters={r\"\\texttt{lr}\": format_sctf},\n",
    "        column_format= \"l\" + n_cols*r\"p{2.3cm}\" \n",
    "    )\n",
    "\n",
    "\n",
    "for key, study in studies.items():\n",
    "    (\n",
    "        Sweep(study)\n",
    "        .summary()\n",
    "        .drop(columns=\"datetime_start\")\n",
    "        .head(10)\n",
    "        .rename(columns=rename_cols)\n",
    "        .pipe(to_latex)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in studies:\n",
    "    print(\n",
    "f\"\"\"\n",
    "\\\\begin{{table}}[htbp]\n",
    "    \\\\centering\n",
    "    \\\\resizebox{{\n",
    "        \\\\ifdim\\\\width>\\\\columnwidth\n",
    "        \\\\columnwidth\n",
    "      \\\\else\n",
    "        \\\\width\n",
    "      \\\\fi\n",
    "    }}{{!}}{{\\\\small\n",
    "    \\\\input{{Tables/{key}-hparams}}\n",
    "    }}\n",
    "    \\\\caption{{Top 10 hyperparameters for INFERENCE according to optuna sweep.}}\n",
    "    \\\\label{{tab:{key}-hparams}}\n",
    "\\end{{table}}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcmc_dir = Path(\"../experiment_results/mnist/2021-12-16/13-07-51/\")\n",
    "mcmc_dir = Path(\"../experiment_results/mnist/2021-12-17/15-58-26/\")\n",
    "mcmc_runs = list(map(Run, mcmc_dir.glob(\"[01]/\")))\n",
    "\n",
    "other_dir  = Path(\"../experiment_results/mnist/2021-12-17/11-01-32/\")\n",
    "other_runs = list(map(Run, other_dir.glob(\"[012]/\")))\n",
    "\n",
    "all_runs = other_runs + mcmc_runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "dm = hydra.utils.instantiate(all_runs[0].cfg.data)\n",
    "dm.setup()\n",
    "n_test = len(dm.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def get_err_incl_ci(error: float) -> str:\n",
    "    pm = sqrt(error * (1 - error) / n_test) * 1.96\n",
    "    return f\"${error:.3} \\\\pm {pm:.2}$\"\n",
    "\n",
    "\n",
    "(\n",
    "    pd.DataFrame.from_dict(\n",
    "        {\n",
    "            run.inference_label: {\"err/test\": run.get_scalar(\"err/test\").iloc[0]}\n",
    "            for run in all_runs\n",
    "        },\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    .apply({\"err/test\" :get_err_incl_ci})\n",
    "    .rename(columns={\"err/test\": \"Test error incl. 95\\\\% CI\"})\n",
    "    .to_latex(\"../thesis/Tables/mnist_test_err.tex\", escape=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweighting MCMC samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_dir_ = Path(\"../experiment_results/mnist/2021-12-19/20-34-46/\")\n",
    "mcmc_runs_ = list(map(Run, mcmc_dir_.glob(\"[01]/\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.concat(\n",
    "        pd.read_json(r.dir / \"sample_resampling_curve.json\")\n",
    "        .rename_axis(index=[\"n_sampled\"])\n",
    "        .assign(sampler=r.inference_label)\n",
    "        .set_index(\"sampler\", append=True)\n",
    "        .reorder_levels([\"sampler\", \"n_sampled\"])\n",
    "        .sort_index()\n",
    "        for r in mcmc_runs_\n",
    "    )\n",
    "    .reset_index()\n",
    "    .pipe((sns.relplot, \"data\"), x=\"n_sampled\", y=\"error_rate\", hue=\"sampler\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "# from torch import Tensor\n",
    "\n",
    "\n",
    "# def get_records(data: Dict[int, Dict[int, Tensor]]):\n",
    "#     return pd.DataFrame.from_dict(\n",
    "#         {\n",
    "#             i: pd.Series(\n",
    "#                 {batch_idx: avg.item() for batch_idx, avg in x.items()},\n",
    "#                 name=\"avg_likelihood\",\n",
    "#             ).rename_axis(index=[\"batch\"])\n",
    "#             for i, x in data.items()\n",
    "#         }\n",
    "#     ).rename_axis(columns=\"parameter_sample\")\n",
    "\n",
    "\n",
    "# avg_likelihoods = pd.concat(\n",
    "#     get_records(torch.load(r.dir / \"val_avg_likelihood.pt\"))\n",
    "#     .assign(sampler=r.inference_label)\n",
    "#     .set_index(\"sampler\", append=True)\n",
    "#     .reorder_levels([\"sampler\", \"batch\"])\n",
    "#     for r in mcmc_runs_\n",
    "# )\n",
    "\n",
    "# val_joint_logliks = (\n",
    "#     pd.concat(\n",
    "#         get_records(torch.load(r.dir / \"val_joint_logliks.pt\"))\n",
    "#         .assign(sampler=r.inference_label)\n",
    "#         .set_index(\"sampler\", append=True)\n",
    "#         .reorder_levels([\"sampler\", \"batch\"])\n",
    "#         for r in mcmc_runs_\n",
    "#     )\n",
    "#     .stack(\"parameter_sample\")\n",
    "#     .groupby(level=[\"sampler\", \"parameter_sample\"])\n",
    "#     .sum()\n",
    "#     .sort_index()\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_joint_logliks = (\n",
    "#     pd.DataFrame(\n",
    "#         {\n",
    "#             r.inference_label: pd.Series(\n",
    "#                 {\n",
    "#                     i: x.item()\n",
    "#                     for i, x in torch.load(r.dir / \"train_joint_logliks.pt\").items()\n",
    "#                 }\n",
    "#             )\n",
    "#             for r in mcmc_runs_\n",
    "#         }\n",
    "#     )\n",
    "#     .rename_axis(index=[\"parameter_sample\"], columns=[\"sampler\"])\n",
    "#     .stack(\"sampler\")\n",
    "#     .reorder_levels([\"sampler\", \"parameter_sample\"])\n",
    "#     .sort_index()\n",
    "# )\n",
    "# train_joint_logliks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_ratio = torch.tensor((val_joint_logliks/10_000 - train_joint_logliks/50_000).values)\n",
    "# un_normalized_weights = log_ratio.exp()\n",
    "# weights = un_normalized_weights / un_normalized_weights.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion is that validation and training are too different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_dir_ = Path(\"../experiment_results/mnist/2021-12-19/20-34-23/\")\n",
    "other_runs_ = list(map(Run, other_dir_.glob(\"[012]/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "in_file = Path(\"tmp.csv\")\n",
    "out_file = Path(\"../thesis/Figures/mnist-calibration.pdf\")\n",
    "pd.concat(\n",
    "    pd.read_csv(r.dir / \"calibration_data.csv\", index_col=0).assign(\n",
    "        inference=r.inference_label\n",
    "    )\n",
    "    for r in mcmc_runs_ + other_runs_\n",
    ").to_csv(in_file)\n",
    "\n",
    "cmd = (\n",
    "    f\"IN_FILE={in_file.resolve().absolute()} \"\n",
    "    f\"OUT_FILE={out_file.resolve().absolute()} \"\n",
    "    \"Rscript ../src/visualization/calibration_curves.r\"\n",
    ")\n",
    "os.system(cmd)\n",
    "in_file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking SGHMC assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "temperatures = pd.concat(\n",
    "    pd.DataFrame.from_dict(\n",
    "        torch.load(run.dir / \"temperature_samples.pt\"),\n",
    "        orient=\"index\",\n",
    "    )\n",
    "    .rename_axis(index=[\"step\", \"parameter\"])\n",
    "    .loc[lambda x: x.index.get_level_values(\"step\") % 50 == 0]\n",
    "    .assign(Sampler=\"\\n\".join(wrap(run.inference_label, width=12)))\n",
    "    .set_index(\"Sampler\", append=True)\n",
    "    .reorder_levels([\"Sampler\", \"parameter\", \"step\"])\n",
    "    for run in mcmc_runs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "global black_line\n",
    "\n",
    "\n",
    "def plot_chi2(df, **kwargs):\n",
    "    global black_line\n",
    "    xlim = plt.gca().axes.get_xlim()\n",
    "    xx = np.linspace(*xlim, 300)\n",
    "    yy = chi2(df.iloc[0]).pdf(xx)\n",
    "    black_line = plt.plot(xx, yy, color=\"black\", label=\"true\")\n",
    "\n",
    "\n",
    "fg = sns.displot(\n",
    "    data=temperatures.reset_index(),\n",
    "    x=\"temperature_sum\",\n",
    "    hue=\"Sampler\",\n",
    "    kind=\"kde\",\n",
    "    col=\"parameter\",\n",
    "    height=1.8,\n",
    "    col_wrap=2,\n",
    "    aspect=2,\n",
    "    common_norm=False,\n",
    "    facet_kws={\"sharex\": False, \"sharey\": False},\n",
    ")\n",
    "fg.map(plot_chi2, \"n_params\")\n",
    "\n",
    "handles = fg.legend.legendHandles\n",
    "texts = [t.get_text() for t in fg.legend.texts]\n",
    "fg.legend.remove()  # Remove seaborn legens\n",
    "\n",
    "handles += black_line\n",
    "texts += [\"True\\ndistribution\"]\n",
    "\n",
    "plt.subplots_adjust(bottom=0.2, right=1)\n",
    "fg.set_xlabels(\"Temperature\")\n",
    "plt.figlegend(\n",
    "    dict(zip(texts, handles)),\n",
    "    title=\"Sampler\",\n",
    "    ncol=3,\n",
    "    frameon=False,\n",
    "    loc=\"lower center\",\n",
    ")\n",
    "plt.savefig(\"../thesis/Figures/mnist-temperatures.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ce311d752f7559aeab697e045d55b95fb71177de97c9fd9eefeb88845310a84"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
