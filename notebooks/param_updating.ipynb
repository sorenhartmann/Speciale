{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.distributions import Gamma, Normal\n",
    "\n",
    "class BayesianMixin(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def setup_prior(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def log_prior(self):\n",
    "        pass\n",
    "\n",
    "class BayesianLinear(BayesianMixin, nn.Linear):\n",
    "\n",
    "    precision : torch.Tensor\n",
    "    alpha : torch.Tensor\n",
    "    beta : nn.Parameter\n",
    "\n",
    "    def setup_prior(self, alpha, beta):\n",
    "        \n",
    "        self.register_parameter(\"precision\", nn.Parameter(torch.tensor(1.)))\n",
    "        self.register_buffer(\"alpha\", torch.tensor(alpha))\n",
    "        self.register_buffer(\"beta\", torch.tensor(beta))\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def log_prior(self):\n",
    "\n",
    "        precision_d = Gamma(self.alpha, self.beta)\n",
    "        param_d = Normal(0, self.precision)\n",
    "\n",
    "        return (\n",
    "            precision_d.log_prob(self.precision) \n",
    "            + param_d.log_prob(self.weight).sum()\n",
    "            + param_d.log_prob(self.bias).sum()\n",
    "        )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from src.models.simple import PolynomialToyModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "true_coeffs = torch.tensor([1.0, 2.0, 0.0, -1.0])\n",
    "t = PolynomialToyModel(true_coeffs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "d = t.generate_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "d.tensors"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-1.0194],\n",
       "         [ 0.0828],\n",
       "         [-1.2416],\n",
       "         [ 0.9428],\n",
       "         [-2.1301],\n",
       "         [ 1.8326],\n",
       "         [-1.8171],\n",
       "         [-1.9876],\n",
       "         [-1.5797],\n",
       "         [ 1.1322],\n",
       "         [-0.9237],\n",
       "         [ 0.9355],\n",
       "         [-2.1218],\n",
       "         [-1.5168],\n",
       "         [-0.9179],\n",
       "         [-0.4913],\n",
       "         [-1.9072],\n",
       "         [ 1.6370],\n",
       "         [-0.5896],\n",
       "         [ 0.8025],\n",
       "         [ 1.7679],\n",
       "         [ 0.4658],\n",
       "         [ 0.6836],\n",
       "         [ 2.4131],\n",
       "         [-1.1275],\n",
       "         [ 0.7919],\n",
       "         [-1.1123],\n",
       "         [ 1.7866],\n",
       "         [ 1.9966],\n",
       "         [-2.3049],\n",
       "         [ 2.1341],\n",
       "         [ 1.1938],\n",
       "         [ 1.0894],\n",
       "         [ 1.0292],\n",
       "         [ 2.0782],\n",
       "         [-0.3301],\n",
       "         [-2.1142],\n",
       "         [-0.7174],\n",
       "         [-1.7607],\n",
       "         [ 0.1653],\n",
       "         [-0.4668],\n",
       "         [-1.3410],\n",
       "         [-0.2273],\n",
       "         [ 2.3685],\n",
       "         [-0.1972],\n",
       "         [ 0.0794],\n",
       "         [-0.3899],\n",
       "         [ 0.3930],\n",
       "         [ 2.2275],\n",
       "         [ 1.5287],\n",
       "         [ 0.8874],\n",
       "         [ 0.5433],\n",
       "         [ 0.5895],\n",
       "         [ 0.9658],\n",
       "         [-0.3231],\n",
       "         [-2.3235],\n",
       "         [-1.5460],\n",
       "         [ 2.1340],\n",
       "         [ 0.1494],\n",
       "         [-2.0252],\n",
       "         [ 0.3943],\n",
       "         [ 2.0657],\n",
       "         [-2.3625],\n",
       "         [-1.6831],\n",
       "         [-0.9957],\n",
       "         [ 0.1003],\n",
       "         [-0.5831],\n",
       "         [-0.2747],\n",
       "         [-2.4372],\n",
       "         [ 1.1707],\n",
       "         [ 2.1944],\n",
       "         [ 1.5281],\n",
       "         [-1.7703],\n",
       "         [-2.0153],\n",
       "         [ 1.0381],\n",
       "         [ 0.0561],\n",
       "         [ 1.0248],\n",
       "         [-2.4429],\n",
       "         [-0.1491],\n",
       "         [ 1.7631],\n",
       "         [ 1.1598],\n",
       "         [ 0.0913],\n",
       "         [ 0.4915],\n",
       "         [-0.2367],\n",
       "         [-1.3746],\n",
       "         [-0.9447],\n",
       "         [-1.5224],\n",
       "         [ 2.0765],\n",
       "         [ 1.3757],\n",
       "         [ 0.8743],\n",
       "         [-1.9171],\n",
       "         [ 1.9291],\n",
       "         [ 0.7839],\n",
       "         [ 1.7295],\n",
       "         [-0.9835],\n",
       "         [ 0.5300],\n",
       "         [ 2.4410],\n",
       "         [ 1.6816],\n",
       "         [ 2.0050],\n",
       "         [-0.5250]]),\n",
       " tensor([[-1.1280e-02],\n",
       "         [ 6.8610e-01],\n",
       "         [ 1.1977e+00],\n",
       "         [ 2.0751e+00],\n",
       "         [ 6.4527e+00],\n",
       "         [-2.4134e+00],\n",
       "         [ 2.3049e+00],\n",
       "         [ 2.5525e+00],\n",
       "         [-2.8006e-01],\n",
       "         [ 1.8194e+00],\n",
       "         [-1.0488e+00],\n",
       "         [ 2.7539e+00],\n",
       "         [ 5.3268e+00],\n",
       "         [ 1.7332e+00],\n",
       "         [ 5.8308e-01],\n",
       "         [-7.5969e-01],\n",
       "         [ 4.6153e+00],\n",
       "         [-1.2672e-01],\n",
       "         [-2.4888e-01],\n",
       "         [ 1.3241e+00],\n",
       "         [-1.5766e+00],\n",
       "         [ 3.0257e+00],\n",
       "         [ 8.3819e-01],\n",
       "         [-8.7821e+00],\n",
       "         [ 1.0128e-01],\n",
       "         [ 3.3646e+00],\n",
       "         [-1.3081e+00],\n",
       "         [-3.2892e+00],\n",
       "         [-3.6732e+00],\n",
       "         [ 7.7133e+00],\n",
       "         [-5.5610e-01],\n",
       "         [ 1.0836e+00],\n",
       "         [ 7.0384e-01],\n",
       "         [ 1.6805e+00],\n",
       "         [-4.4240e+00],\n",
       "         [ 9.7601e-01],\n",
       "         [ 4.8018e+00],\n",
       "         [-2.8940e-01],\n",
       "         [ 3.3673e+00],\n",
       "         [ 4.2716e-01],\n",
       "         [ 1.5030e-01],\n",
       "         [ 1.1558e+00],\n",
       "         [-2.0860e-01],\n",
       "         [-7.6044e+00],\n",
       "         [-1.1876e-01],\n",
       "         [ 2.3930e+00],\n",
       "         [ 1.4657e+00],\n",
       "         [ 1.5052e+00],\n",
       "         [-5.3921e+00],\n",
       "         [-1.2180e-02],\n",
       "         [ 2.6580e+00],\n",
       "         [ 2.1315e+00],\n",
       "         [ 9.8975e-01],\n",
       "         [ 3.9491e+00],\n",
       "         [ 1.3350e+00],\n",
       "         [ 1.0581e+01],\n",
       "         [ 2.0871e+00],\n",
       "         [-4.5847e+00],\n",
       "         [ 1.5074e+00],\n",
       "         [ 4.3843e+00],\n",
       "         [ 9.7161e-01],\n",
       "         [-3.8813e+00],\n",
       "         [ 1.0673e+01],\n",
       "         [ 1.1942e+00],\n",
       "         [-2.2620e+00],\n",
       "         [-6.0127e-01],\n",
       "         [ 7.3356e-01],\n",
       "         [ 1.0416e+00],\n",
       "         [ 1.2482e+01],\n",
       "         [ 8.1766e-01],\n",
       "         [-4.1457e+00],\n",
       "         [ 6.0744e-02],\n",
       "         [ 3.0960e+00],\n",
       "         [ 3.9503e+00],\n",
       "         [ 3.0539e+00],\n",
       "         [ 3.5331e+00],\n",
       "         [ 2.2182e+00],\n",
       "         [ 1.2504e+01],\n",
       "         [ 2.6279e-01],\n",
       "         [-1.2090e+00],\n",
       "         [ 2.4401e+00],\n",
       "         [ 2.3882e+00],\n",
       "         [ 3.4893e+00],\n",
       "         [ 8.8581e-01],\n",
       "         [-3.1990e-04],\n",
       "         [ 4.8604e-01],\n",
       "         [ 5.4952e-01],\n",
       "         [-4.6439e+00],\n",
       "         [ 1.0132e+00],\n",
       "         [ 2.5482e+00],\n",
       "         [ 3.4168e+00],\n",
       "         [-3.2382e+00],\n",
       "         [ 2.5048e+00],\n",
       "         [-1.8265e+00],\n",
       "         [ 1.1070e+00],\n",
       "         [ 2.1757e+00],\n",
       "         [-9.1318e+00],\n",
       "         [ 6.9434e-01],\n",
       "         [-3.9393e+00],\n",
       "         [ 8.5943e-01]]))"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "class BayesianModel(nn.Module):\n",
    "\n",
    "    def log_prior(self):\n",
    "        return sum(\n",
    "\n",
    "            m.log_prior() for m in self.modules() if isinstance(m, BayesianMixin)\n",
    "        )\n",
    "    @abstractmethod\n",
    "    def log_likelihood(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "net.log_likelihood(torch.Tensor([[1., 2., 3., 4.]]), torch.tensor([2]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(-1.0619, grad_fn=<SumBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "from src.models.simple import ClassifierNet\n",
    "import copy\n",
    "net = ClassifierNet(4, 3, [200, 200, 200])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "%%timeit\n",
    "t = copy.deepcopy(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "814 µs ± 74.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "%%timeit\n",
    "t = "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "114 µs ± 806 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for param in t.parameters():\n",
    "    print(t.prior_distribution.log_prob(param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.9192, -0.9191, -0.9190,  ..., -0.9193, -0.9194, -0.9189],\n",
      "        [-0.9194, -0.9190, -0.9189,  ..., -0.9193, -0.9193, -0.9190],\n",
      "        [-0.9195, -0.9191, -0.9189,  ..., -0.9189, -0.9196, -0.9189],\n",
      "        ...,\n",
      "        [-0.9194, -0.9193, -0.9190,  ..., -0.9190, -0.9195, -0.9191],\n",
      "        [-0.9195, -0.9189, -0.9190,  ..., -0.9192, -0.9189, -0.9191],\n",
      "        [-0.9190, -0.9190, -0.9189,  ..., -0.9195, -0.9189, -0.9190]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([-0.9192, -0.9189, -0.9191, -0.9189, -0.9191, -0.9189, -0.9189, -0.9194,\n",
      "        -0.9190, -0.9189, -0.9190, -0.9190, -0.9194, -0.9190, -0.9193, -0.9191,\n",
      "        -0.9190, -0.9191, -0.9191, -0.9190, -0.9190, -0.9195, -0.9193, -0.9190,\n",
      "        -0.9189, -0.9191, -0.9195, -0.9192, -0.9194, -0.9193, -0.9191, -0.9191,\n",
      "        -0.9190, -0.9190, -0.9190, -0.9189, -0.9190, -0.9192, -0.9194, -0.9189,\n",
      "        -0.9193, -0.9190, -0.9189, -0.9189, -0.9191, -0.9191, -0.9190, -0.9192,\n",
      "        -0.9190, -0.9190, -0.9190, -0.9195, -0.9190, -0.9191, -0.9190, -0.9190,\n",
      "        -0.9194, -0.9192, -0.9192, -0.9189, -0.9191, -0.9190, -0.9194, -0.9189,\n",
      "        -0.9192, -0.9189, -0.9189, -0.9195, -0.9190, -0.9191, -0.9192, -0.9189,\n",
      "        -0.9189, -0.9189, -0.9190, -0.9191, -0.9191, -0.9191, -0.9191, -0.9190,\n",
      "        -0.9190, -0.9191, -0.9190, -0.9196, -0.9195, -0.9194, -0.9191, -0.9191,\n",
      "        -0.9193, -0.9189, -0.9189, -0.9190, -0.9194, -0.9190, -0.9190, -0.9193,\n",
      "        -0.9190, -0.9193, -0.9192, -0.9194], grad_fn=<SubBackward0>)\n",
      "tensor([[-0.9194, -0.9232, -0.9205, -0.9201, -0.9196, -0.9190, -0.9211, -0.9217,\n",
      "         -0.9236, -0.9191, -0.9200, -0.9214, -0.9206, -0.9189, -0.9206, -0.9198,\n",
      "         -0.9191, -0.9196, -0.9200, -0.9215, -0.9193, -0.9223, -0.9191, -0.9236,\n",
      "         -0.9212, -0.9203, -0.9201, -0.9194, -0.9192, -0.9207, -0.9197, -0.9190,\n",
      "         -0.9191, -0.9223, -0.9206, -0.9211, -0.9198, -0.9193, -0.9196, -0.9190,\n",
      "         -0.9204, -0.9208, -0.9191, -0.9190, -0.9200, -0.9222, -0.9221, -0.9239,\n",
      "         -0.9190, -0.9192, -0.9239, -0.9203, -0.9195, -0.9190, -0.9196, -0.9192,\n",
      "         -0.9202, -0.9236, -0.9219, -0.9194, -0.9216, -0.9195, -0.9191, -0.9208,\n",
      "         -0.9196, -0.9194, -0.9194, -0.9227, -0.9196, -0.9233, -0.9199, -0.9219,\n",
      "         -0.9204, -0.9191, -0.9195, -0.9190, -0.9200, -0.9213, -0.9195, -0.9197,\n",
      "         -0.9238, -0.9222, -0.9229, -0.9192, -0.9235, -0.9194, -0.9202, -0.9204,\n",
      "         -0.9206, -0.9197, -0.9201, -0.9189, -0.9238, -0.9206, -0.9202, -0.9192,\n",
      "         -0.9193, -0.9190, -0.9199, -0.9220],\n",
      "        [-0.9196, -0.9195, -0.9189, -0.9211, -0.9192, -0.9210, -0.9232, -0.9212,\n",
      "         -0.9222, -0.9190, -0.9197, -0.9222, -0.9211, -0.9204, -0.9209, -0.9190,\n",
      "         -0.9193, -0.9232, -0.9222, -0.9202, -0.9210, -0.9217, -0.9220, -0.9196,\n",
      "         -0.9191, -0.9213, -0.9232, -0.9221, -0.9196, -0.9192, -0.9231, -0.9203,\n",
      "         -0.9216, -0.9198, -0.9213, -0.9198, -0.9201, -0.9232, -0.9202, -0.9218,\n",
      "         -0.9195, -0.9199, -0.9191, -0.9202, -0.9198, -0.9190, -0.9189, -0.9206,\n",
      "         -0.9237, -0.9190, -0.9199, -0.9232, -0.9230, -0.9208, -0.9209, -0.9194,\n",
      "         -0.9203, -0.9198, -0.9210, -0.9196, -0.9226, -0.9229, -0.9197, -0.9233,\n",
      "         -0.9190, -0.9214, -0.9192, -0.9190, -0.9215, -0.9204, -0.9232, -0.9190,\n",
      "         -0.9191, -0.9206, -0.9189, -0.9208, -0.9226, -0.9223, -0.9202, -0.9230,\n",
      "         -0.9218, -0.9220, -0.9206, -0.9214, -0.9194, -0.9220, -0.9194, -0.9197,\n",
      "         -0.9219, -0.9199, -0.9206, -0.9190, -0.9194, -0.9225, -0.9210, -0.9203,\n",
      "         -0.9225, -0.9191, -0.9233, -0.9209],\n",
      "        [-0.9192, -0.9215, -0.9190, -0.9197, -0.9195, -0.9234, -0.9190, -0.9204,\n",
      "         -0.9190, -0.9229, -0.9231, -0.9220, -0.9199, -0.9190, -0.9209, -0.9217,\n",
      "         -0.9191, -0.9214, -0.9205, -0.9208, -0.9233, -0.9226, -0.9204, -0.9196,\n",
      "         -0.9198, -0.9223, -0.9215, -0.9190, -0.9209, -0.9200, -0.9190, -0.9206,\n",
      "         -0.9224, -0.9193, -0.9200, -0.9193, -0.9238, -0.9206, -0.9219, -0.9213,\n",
      "         -0.9224, -0.9205, -0.9222, -0.9229, -0.9203, -0.9237, -0.9209, -0.9198,\n",
      "         -0.9190, -0.9193, -0.9201, -0.9205, -0.9193, -0.9213, -0.9201, -0.9195,\n",
      "         -0.9195, -0.9215, -0.9233, -0.9195, -0.9239, -0.9206, -0.9210, -0.9234,\n",
      "         -0.9191, -0.9229, -0.9192, -0.9228, -0.9189, -0.9204, -0.9206, -0.9229,\n",
      "         -0.9194, -0.9210, -0.9225, -0.9191, -0.9197, -0.9202, -0.9194, -0.9191,\n",
      "         -0.9194, -0.9217, -0.9200, -0.9190, -0.9207, -0.9220, -0.9193, -0.9206,\n",
      "         -0.9238, -0.9225, -0.9214, -0.9193, -0.9190, -0.9224, -0.9190, -0.9200,\n",
      "         -0.9192, -0.9194, -0.9197, -0.9221],\n",
      "        [-0.9224, -0.9221, -0.9216, -0.9223, -0.9191, -0.9199, -0.9203, -0.9229,\n",
      "         -0.9200, -0.9239, -0.9196, -0.9220, -0.9195, -0.9193, -0.9193, -0.9202,\n",
      "         -0.9189, -0.9205, -0.9196, -0.9203, -0.9192, -0.9207, -0.9193, -0.9190,\n",
      "         -0.9221, -0.9190, -0.9193, -0.9202, -0.9190, -0.9200, -0.9193, -0.9190,\n",
      "         -0.9190, -0.9198, -0.9192, -0.9191, -0.9219, -0.9217, -0.9203, -0.9190,\n",
      "         -0.9189, -0.9218, -0.9211, -0.9196, -0.9208, -0.9191, -0.9207, -0.9229,\n",
      "         -0.9191, -0.9192, -0.9234, -0.9190, -0.9231, -0.9214, -0.9232, -0.9199,\n",
      "         -0.9190, -0.9189, -0.9190, -0.9194, -0.9233, -0.9216, -0.9222, -0.9206,\n",
      "         -0.9190, -0.9194, -0.9226, -0.9190, -0.9195, -0.9199, -0.9194, -0.9213,\n",
      "         -0.9219, -0.9205, -0.9205, -0.9199, -0.9223, -0.9223, -0.9196, -0.9232,\n",
      "         -0.9202, -0.9233, -0.9238, -0.9192, -0.9212, -0.9191, -0.9230, -0.9199,\n",
      "         -0.9204, -0.9222, -0.9206, -0.9237, -0.9234, -0.9231, -0.9227, -0.9213,\n",
      "         -0.9189, -0.9200, -0.9202, -0.9201],\n",
      "        [-0.9190, -0.9213, -0.9199, -0.9232, -0.9193, -0.9189, -0.9208, -0.9197,\n",
      "         -0.9190, -0.9198, -0.9201, -0.9198, -0.9239, -0.9190, -0.9232, -0.9209,\n",
      "         -0.9235, -0.9206, -0.9193, -0.9196, -0.9191, -0.9190, -0.9228, -0.9206,\n",
      "         -0.9239, -0.9194, -0.9189, -0.9194, -0.9215, -0.9191, -0.9193, -0.9216,\n",
      "         -0.9202, -0.9239, -0.9205, -0.9218, -0.9227, -0.9192, -0.9193, -0.9230,\n",
      "         -0.9192, -0.9233, -0.9198, -0.9192, -0.9205, -0.9206, -0.9190, -0.9191,\n",
      "         -0.9210, -0.9191, -0.9203, -0.9189, -0.9216, -0.9192, -0.9237, -0.9191,\n",
      "         -0.9204, -0.9195, -0.9207, -0.9222, -0.9222, -0.9222, -0.9190, -0.9225,\n",
      "         -0.9193, -0.9189, -0.9203, -0.9207, -0.9192, -0.9191, -0.9214, -0.9198,\n",
      "         -0.9228, -0.9218, -0.9207, -0.9190, -0.9217, -0.9189, -0.9200, -0.9193,\n",
      "         -0.9195, -0.9215, -0.9203, -0.9207, -0.9204, -0.9189, -0.9190, -0.9239,\n",
      "         -0.9201, -0.9190, -0.9208, -0.9189, -0.9237, -0.9222, -0.9190, -0.9203,\n",
      "         -0.9192, -0.9231, -0.9190, -0.9192],\n",
      "        [-0.9194, -0.9231, -0.9224, -0.9212, -0.9201, -0.9211, -0.9228, -0.9217,\n",
      "         -0.9200, -0.9221, -0.9220, -0.9209, -0.9234, -0.9202, -0.9190, -0.9228,\n",
      "         -0.9215, -0.9194, -0.9197, -0.9190, -0.9195, -0.9224, -0.9238, -0.9218,\n",
      "         -0.9192, -0.9232, -0.9235, -0.9198, -0.9235, -0.9222, -0.9190, -0.9189,\n",
      "         -0.9207, -0.9205, -0.9200, -0.9201, -0.9200, -0.9190, -0.9207, -0.9200,\n",
      "         -0.9192, -0.9193, -0.9190, -0.9199, -0.9196, -0.9190, -0.9236, -0.9201,\n",
      "         -0.9197, -0.9211, -0.9198, -0.9196, -0.9193, -0.9200, -0.9189, -0.9213,\n",
      "         -0.9235, -0.9192, -0.9203, -0.9210, -0.9201, -0.9189, -0.9190, -0.9190,\n",
      "         -0.9202, -0.9193, -0.9193, -0.9191, -0.9210, -0.9224, -0.9191, -0.9209,\n",
      "         -0.9239, -0.9189, -0.9207, -0.9190, -0.9195, -0.9199, -0.9196, -0.9233,\n",
      "         -0.9217, -0.9192, -0.9230, -0.9201, -0.9205, -0.9230, -0.9194, -0.9192,\n",
      "         -0.9195, -0.9190, -0.9202, -0.9230, -0.9190, -0.9208, -0.9218, -0.9216,\n",
      "         -0.9221, -0.9197, -0.9190, -0.9211],\n",
      "        [-0.9229, -0.9192, -0.9194, -0.9193, -0.9199, -0.9201, -0.9236, -0.9197,\n",
      "         -0.9190, -0.9190, -0.9192, -0.9201, -0.9238, -0.9190, -0.9199, -0.9229,\n",
      "         -0.9198, -0.9204, -0.9229, -0.9191, -0.9203, -0.9226, -0.9205, -0.9189,\n",
      "         -0.9233, -0.9194, -0.9225, -0.9194, -0.9238, -0.9223, -0.9189, -0.9201,\n",
      "         -0.9202, -0.9211, -0.9190, -0.9203, -0.9214, -0.9194, -0.9206, -0.9236,\n",
      "         -0.9229, -0.9216, -0.9211, -0.9215, -0.9222, -0.9192, -0.9210, -0.9234,\n",
      "         -0.9209, -0.9190, -0.9230, -0.9194, -0.9199, -0.9212, -0.9199, -0.9219,\n",
      "         -0.9190, -0.9192, -0.9228, -0.9193, -0.9237, -0.9223, -0.9220, -0.9200,\n",
      "         -0.9192, -0.9191, -0.9235, -0.9207, -0.9229, -0.9231, -0.9223, -0.9215,\n",
      "         -0.9227, -0.9202, -0.9213, -0.9232, -0.9194, -0.9218, -0.9200, -0.9194,\n",
      "         -0.9198, -0.9205, -0.9216, -0.9193, -0.9191, -0.9199, -0.9226, -0.9200,\n",
      "         -0.9197, -0.9218, -0.9221, -0.9214, -0.9214, -0.9219, -0.9191, -0.9215,\n",
      "         -0.9224, -0.9201, -0.9192, -0.9214],\n",
      "        [-0.9233, -0.9191, -0.9234, -0.9231, -0.9189, -0.9230, -0.9237, -0.9207,\n",
      "         -0.9193, -0.9231, -0.9210, -0.9216, -0.9216, -0.9222, -0.9209, -0.9190,\n",
      "         -0.9207, -0.9208, -0.9217, -0.9203, -0.9214, -0.9234, -0.9219, -0.9208,\n",
      "         -0.9203, -0.9218, -0.9203, -0.9196, -0.9212, -0.9195, -0.9211, -0.9192,\n",
      "         -0.9236, -0.9189, -0.9190, -0.9210, -0.9228, -0.9189, -0.9232, -0.9191,\n",
      "         -0.9207, -0.9191, -0.9231, -0.9213, -0.9194, -0.9222, -0.9200, -0.9229,\n",
      "         -0.9194, -0.9215, -0.9189, -0.9201, -0.9202, -0.9190, -0.9220, -0.9189,\n",
      "         -0.9202, -0.9209, -0.9193, -0.9202, -0.9209, -0.9213, -0.9225, -0.9235,\n",
      "         -0.9239, -0.9190, -0.9198, -0.9219, -0.9206, -0.9236, -0.9216, -0.9191,\n",
      "         -0.9196, -0.9191, -0.9231, -0.9192, -0.9209, -0.9190, -0.9202, -0.9190,\n",
      "         -0.9218, -0.9199, -0.9210, -0.9191, -0.9230, -0.9231, -0.9209, -0.9196,\n",
      "         -0.9206, -0.9191, -0.9216, -0.9212, -0.9194, -0.9232, -0.9236, -0.9216,\n",
      "         -0.9189, -0.9229, -0.9191, -0.9226],\n",
      "        [-0.9216, -0.9221, -0.9197, -0.9206, -0.9191, -0.9220, -0.9218, -0.9214,\n",
      "         -0.9207, -0.9191, -0.9195, -0.9208, -0.9190, -0.9201, -0.9231, -0.9200,\n",
      "         -0.9236, -0.9202, -0.9197, -0.9200, -0.9213, -0.9199, -0.9202, -0.9226,\n",
      "         -0.9201, -0.9205, -0.9209, -0.9192, -0.9199, -0.9193, -0.9211, -0.9195,\n",
      "         -0.9191, -0.9228, -0.9201, -0.9224, -0.9195, -0.9191, -0.9204, -0.9196,\n",
      "         -0.9229, -0.9216, -0.9225, -0.9194, -0.9195, -0.9195, -0.9204, -0.9199,\n",
      "         -0.9226, -0.9196, -0.9228, -0.9202, -0.9228, -0.9210, -0.9189, -0.9190,\n",
      "         -0.9201, -0.9193, -0.9204, -0.9198, -0.9209, -0.9204, -0.9218, -0.9190,\n",
      "         -0.9231, -0.9226, -0.9202, -0.9210, -0.9189, -0.9201, -0.9215, -0.9210,\n",
      "         -0.9210, -0.9201, -0.9196, -0.9235, -0.9232, -0.9229, -0.9199, -0.9208,\n",
      "         -0.9189, -0.9189, -0.9230, -0.9193, -0.9189, -0.9200, -0.9198, -0.9230,\n",
      "         -0.9202, -0.9202, -0.9193, -0.9204, -0.9189, -0.9192, -0.9192, -0.9201,\n",
      "         -0.9230, -0.9196, -0.9199, -0.9193],\n",
      "        [-0.9207, -0.9190, -0.9224, -0.9207, -0.9195, -0.9191, -0.9231, -0.9190,\n",
      "         -0.9213, -0.9202, -0.9208, -0.9198, -0.9208, -0.9206, -0.9215, -0.9191,\n",
      "         -0.9195, -0.9191, -0.9218, -0.9221, -0.9199, -0.9201, -0.9196, -0.9217,\n",
      "         -0.9209, -0.9190, -0.9192, -0.9207, -0.9205, -0.9194, -0.9216, -0.9228,\n",
      "         -0.9193, -0.9207, -0.9192, -0.9191, -0.9199, -0.9190, -0.9190, -0.9229,\n",
      "         -0.9190, -0.9198, -0.9197, -0.9232, -0.9191, -0.9212, -0.9233, -0.9231,\n",
      "         -0.9193, -0.9208, -0.9192, -0.9192, -0.9218, -0.9200, -0.9189, -0.9191,\n",
      "         -0.9189, -0.9202, -0.9189, -0.9191, -0.9191, -0.9197, -0.9207, -0.9196,\n",
      "         -0.9229, -0.9190, -0.9206, -0.9211, -0.9202, -0.9229, -0.9191, -0.9207,\n",
      "         -0.9230, -0.9191, -0.9191, -0.9190, -0.9191, -0.9221, -0.9194, -0.9210,\n",
      "         -0.9190, -0.9221, -0.9189, -0.9194, -0.9199, -0.9190, -0.9204, -0.9199,\n",
      "         -0.9196, -0.9220, -0.9202, -0.9216, -0.9223, -0.9233, -0.9197, -0.9215,\n",
      "         -0.9218, -0.9199, -0.9189, -0.9208]], grad_fn=<SubBackward0>)\n",
      "tensor([-0.9230, -0.9193, -0.9193, -0.9192, -0.9222, -0.9200, -0.9194, -0.9197,\n",
      "        -0.9190, -0.9202], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "d767b8386092d7cf7d2b9cae3bbc1311fb6c0ac52cead8f221dab1753f4d4fb8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}