\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}

intro

teori

We implement both of these approaches using the PyTorch and PyTorch Lightning frameworks.

We implement two different approaches, the first being a Markov chain Monte Carlo algorithm, SGHMC introduced in \cite*{chen_stochastic_2014}.
This algorithm is a variation of the Hamiltonian Monte Carlo algorithm, allowing for sampling in a batched learning environment.
SGHMC accomplishes this by modifying the stochastic dynamic to correct for the additional variance by introducing a friction term. 
This approach works well in small-scale simulated experiments. 
We also find that introducing a gradient variance estimator for these simulated scenarios can improve the performance of the sampling algorithm.
The second approach is approximating the Bayesian posterior using the variational inference algorithm.

hurtig konklu

% \blindtext





