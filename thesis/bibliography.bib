
@article{wilson_bayesian_2020,
	title = {Bayesian Deep Learning and a Probabilistic Perspective of Generalization},
	url = {http://arxiv.org/abs/2002.08791},
	abstract = {The key distinguishing property of a Bayesian approach is marginalization, rather than using a single setting of weights. Bayesian marginalization can particularly improve the accuracy and calibration of modern deep neural networks, which are typically underspecified by the data, and can represent many compelling but different solutions. We show that deep ensembles provide an effective mechanism for approximate Bayesian marginalization, and propose a related approach that further improves the predictive distribution by marginalizing within basins of attraction, without significant overhead. We also investigate the prior over functions implied by a vague distribution over neural network weights, explaining the generalization properties of such models from a probabilistic perspective. From this perspective, we explain results that have been presented as mysterious and distinct to neural network generalization, such as the ability to fit images with random labels, and show that these results can be reproduced with Gaussian processes. We also show that Bayesian model averaging alleviates double descent, resulting in monotonic performance improvements with increased flexibility. Finally, we provide a Bayesian perspective on tempering for calibrating predictive distributions.},
	journaltitle = {{arXiv}:2002.08791 [cs, stat]},
	author = {Wilson, Andrew Gordon and Izmailov, Pavel},
	urldate = {2021-08-03},
	date = {2020-04-27},
	eprinttype = {arxiv},
	eprint = {2002.08791},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/IJJPQMYP/Wilson and Izmailov - 2020 - Bayesian Deep Learning and a Probabilistic Perspec.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/J9NWLJTI/2002.html:text/html;Wilson - Bayesian Deep Learning and a Probabilistic Perspec.pdf:/Users/soren/Zotero/storage/UFS2UV7Y/Wilson - Bayesian Deep Learning and a Probabilistic Perspec.pdf:application/pdf},
}

@book{bishop_pattern_2006,
	location = {New York},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	series = {Information science and statistics},
	pagetotal = {738},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	date = {2006},
	keywords = {Machine learning, Pattern perception},
}

@article{blundell_weight_2015,
	title = {Weight Uncertainty in Neural Networks},
	url = {http://arxiv.org/abs/1505.05424},
	abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on {MNIST} classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
	journaltitle = {{arXiv}:1505.05424 [cs, stat]},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	urldate = {2021-08-09},
	date = {2015-05-21},
	eprinttype = {arxiv},
	eprint = {1505.05424},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/S9Q3IYGM/Blundell et al. - 2015 - Weight Uncertainty in Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/GV4CWHQE/1505.html:text/html},
}

@article{chen_stochastic_2014,
	title = {Stochastic Gradient Hamiltonian Monte Carlo},
	url = {http://arxiv.org/abs/1402.4102},
	abstract = {Hamiltonian Monte Carlo ({HMC}) sampling methods provide a mechanism for defining distant proposals with high acceptance probabilities in a Metropolis-Hastings framework, enabling more efficient exploration of the state space than standard random-walk proposals. The popularity of such methods has grown significantly in recent years. However, a limitation of {HMC} methods is the required gradient computation for simulation of the Hamiltonian dynamical system-such computation is infeasible in problems involving a large sample size or streaming data. Instead, we must rely on a noisy gradient estimate computed from a subset of the data. In this paper, we explore the properties of such a stochastic gradient {HMC} approach. Surprisingly, the natural implementation of the stochastic approximation can be arbitrarily bad. To address this problem we introduce a variant that uses second-order Langevin dynamics with a friction term that counteracts the effects of the noisy gradient, maintaining the desired target distribution as the invariant distribution. Results on simulated data validate our theory. We also provide an application of our methods to a classification task using neural networks and to online Bayesian matrix factorization.},
	journaltitle = {{arXiv}:1402.4102 [cs, stat]},
	author = {Chen, Tianqi and Fox, Emily B. and Guestrin, Carlos},
	urldate = {2021-08-09},
	date = {2014-05-12},
	eprinttype = {arxiv},
	eprint = {1402.4102},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/7U2F5GJ8/Chen et al. - 2014 - Stochastic Gradient Hamiltonian Monte Carlo.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/NDACLSW7/1402.html:text/html},
}

@article{ahn_bayesian_2012,
	title = {Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring},
	url = {http://arxiv.org/abs/1206.6380},
	abstract = {In this paper we address the following question: Can we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?. An algorithm based on the Langevin equation with stochastic gradients ({SGLD}) was previously proposed to solve this, but its mixing rate was slow. By leveraging the Bayesian Central Limit Theorem, we extend the {SGLD} algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of {SGLD} with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an efficient optimizer during burn-in.},
	journaltitle = {{arXiv}:1206.6380 [cs, stat]},
	author = {Ahn, Sungjin and Korattikara, Anoop and Welling, Max},
	urldate = {2021-08-10},
	date = {2012-06-27},
	eprinttype = {arxiv},
	eprint = {1206.6380},
	keywords = {Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/DVRXUKCC/Ahn et al. - 2012 - Bayesian Posterior Sampling via Stochastic Gradien.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/S5GGTPJ3/1206.html:text/html},
}