
@article{wilson_bayesian_2020,
	title = {Bayesian {Deep} {Learning} and a {Probabilistic} {Perspective} of {Generalization}},
	url = {http://arxiv.org/abs/2002.08791},
	abstract = {The key distinguishing property of a Bayesian approach is marginalization, rather than using a single setting of weights. Bayesian marginalization can particularly improve the accuracy and calibration of modern deep neural networks, which are typically underspecified by the data, and can represent many compelling but different solutions. We show that deep ensembles provide an effective mechanism for approximate Bayesian marginalization, and propose a related approach that further improves the predictive distribution by marginalizing within basins of attraction, without significant overhead. We also investigate the prior over functions implied by a vague distribution over neural network weights, explaining the generalization properties of such models from a probabilistic perspective. From this perspective, we explain results that have been presented as mysterious and distinct to neural network generalization, such as the ability to fit images with random labels, and show that these results can be reproduced with Gaussian processes. We also show that Bayesian model averaging alleviates double descent, resulting in monotonic performance improvements with increased flexibility. Finally, we provide a Bayesian perspective on tempering for calibrating predictive distributions.},
	urldate = {2021-08-03},
	journal = {arXiv:2002.08791 [cs, stat]},
	author = {Wilson, Andrew Gordon and Izmailov, Pavel},
	month = apr,
	year = {2020},
	note = {arXiv: 2002.08791},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 30 pages, 19 figures. Updated to add new results showing Bayesian model averaging mitigates double descent},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/IJJPQMYP/Wilson and Izmailov - 2020 - Bayesian Deep Learning and a Probabilistic Perspec.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/J9NWLJTI/2002.html:text/html;Wilson - Bayesian Deep Learning and a Probabilistic Perspec.pdf:/Users/soren/Zotero/storage/UFS2UV7Y/Wilson - Bayesian Deep Learning and a Probabilistic Perspec.pdf:application/pdf},
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
}

@article{blundell_weight_2015,
	title = {Weight {Uncertainty} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/1505.05424},
	abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
	urldate = {2021-08-09},
	journal = {arXiv:1505.05424 [cs, stat]},
	author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	month = may,
	year = {2015},
	note = {arXiv: 1505.05424},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: In Proceedings of the 32nd International Conference on Machine Learning (ICML 2015)},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/S9Q3IYGM/Blundell et al. - 2015 - Weight Uncertainty in Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/GV4CWHQE/1505.html:text/html},
}

@article{chen_stochastic_2014,
	title = {Stochastic {Gradient} {Hamiltonian} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1402.4102},
	abstract = {Hamiltonian Monte Carlo (HMC) sampling methods provide a mechanism for defining distant proposals with high acceptance probabilities in a Metropolis-Hastings framework, enabling more efficient exploration of the state space than standard random-walk proposals. The popularity of such methods has grown significantly in recent years. However, a limitation of HMC methods is the required gradient computation for simulation of the Hamiltonian dynamical system-such computation is infeasible in problems involving a large sample size or streaming data. Instead, we must rely on a noisy gradient estimate computed from a subset of the data. In this paper, we explore the properties of such a stochastic gradient HMC approach. Surprisingly, the natural implementation of the stochastic approximation can be arbitrarily bad. To address this problem we introduce a variant that uses second-order Langevin dynamics with a friction term that counteracts the effects of the noisy gradient, maintaining the desired target distribution as the invariant distribution. Results on simulated data validate our theory. We also provide an application of our methods to a classification task using neural networks and to online Bayesian matrix factorization.},
	urldate = {2021-08-09},
	journal = {arXiv:1402.4102 [cs, stat]},
	author = {Chen, Tianqi and Fox, Emily B. and Guestrin, Carlos},
	month = may,
	year = {2014},
	note = {arXiv: 1402.4102},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
	annote = {Comment: ICML 2014 version},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/7U2F5GJ8/Chen et al. - 2014 - Stochastic Gradient Hamiltonian Monte Carlo.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/NDACLSW7/1402.html:text/html},
}

@article{ahn_bayesian_2012,
	title = {Bayesian {Posterior} {Sampling} via {Stochastic} {Gradient} {Fisher} {Scoring}},
	url = {http://arxiv.org/abs/1206.6380},
	abstract = {In this paper we address the following question: Can we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?. An algorithm based on the Langevin equation with stochastic gradients (SGLD) was previously proposed to solve this, but its mixing rate was slow. By leveraging the Bayesian Central Limit Theorem, we extend the SGLD algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an efficient optimizer during burn-in.},
	urldate = {2021-08-10},
	journal = {arXiv:1206.6380 [cs, stat]},
	author = {Ahn, Sungjin and Korattikara, Anoop and Welling, Max},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.6380},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Computation},
	annote = {Comment: Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/DVRXUKCC/Ahn et al. - 2012 - Bayesian Posterior Sampling via Stochastic Gradien.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/S5GGTPJ3/1206.html:text/html},
}

@incollection{li_markov_2010,
	address = {Berlin, Heidelberg},
	title = {Markov {Chains} on {Continuous} {State} {Space}},
	isbn = {978-3-642-11491-5 978-3-642-11492-2},
	url = {http://link.springer.com/10.1007/978-3-642-11492-2_5},
	language = {en},
	urldate = {2021-09-21},
	booktitle = {Constructive {Computation} in {Stochastic} {Models} with {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Li, Quan-Lin},
	collaborator = {Li, Quan-Lin},
	year = {2010},
	doi = {10.1007/978-3-642-11492-2_5},
	pages = {216--287},
	annote = {Markov chains and stationary distributions
Â },
	file = {Li - 5 Markov Chains on Continuous State Space.pdf:/Users/soren/Zotero/storage/EMYHNL9E/Li - 5 Markov Chains on Continuous State Space.pdf:application/pdf},
}

@article{kingma_adam_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2021-09-24},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/WR3XEIS2/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/M6LD85Z9/1412.html:text/html},
}

@article{welford_note_1962,
	title = {Note on a {Method} for {Calculating} {Corrected} {Sums} of {Squares} and {Products}},
	volume = {4},
	issn = {0040-1706, 1537-2723},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1962.10490022},
	doi = {10.1080/00401706.1962.10490022},
	language = {en},
	number = {3},
	urldate = {2021-10-16},
	journal = {Technometrics},
	author = {Welford, B. P.},
	month = aug,
	year = {1962},
	pages = {419--420},
	file = {Welford - 1962 - Note on a Method for Calculating Corrected Sums of.pdf:/Users/soren/Zotero/storage/CGQFVMD9/Welford - 1962 - Note on a Method for Calculating Corrected Sums of.pdf:application/pdf},
}

@article{neal_mcmc_2011,
	title = {{MCMC} using {Hamiltonian} dynamics},
	url = {http://arxiv.org/abs/1206.1901},
	doi = {10.1201/b10905},
	abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard-to-compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, I discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for deciding on acceptance or rejection, computing trajectories using fast approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories from taking much computation time.},
	urldate = {2021-11-01},
	journal = {arXiv:1206.1901 [physics, stat]},
	author = {Neal, Radford M.},
	month = may,
	year = {2011},
	note = {arXiv: 1206.1901},
	keywords = {Statistics - Computation, Physics - Computational Physics},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/Q6PZ5LIJ/Neal - 2011 - MCMC using Hamiltonian dynamics.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/BTDXMQQF/1206.html:text/html},
}

@article{betancourt_conceptual_2018,
	title = {A {Conceptual} {Introduction} to {Hamiltonian} {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1701.02434},
	abstract = {Hamiltonian Monte Carlo has proven a remarkable empirical success, but only recently have we begun to develop a rigorous understanding of why it performs so well on difficult problems and how it is best applied in practice. Unfortunately, that understanding is confined within the mathematics of differential geometry which has limited its dissemination, especially to the applied communities for which it is particularly important. In this review I provide a comprehensive conceptual account of these theoretical foundations, focusing on developing a principled intuition behind the method and its optimal implementations rather of any exhaustive rigor. Whether a practitioner or a statistician, the dedicated reader will acquire a solid grasp of how Hamiltonian Monte Carlo works, when it succeeds, and, perhaps most importantly, when it fails.},
	urldate = {2021-11-02},
	journal = {arXiv:1701.02434 [stat]},
	author = {Betancourt, Michael},
	month = jul,
	year = {2018},
	note = {arXiv: 1701.02434},
	keywords = {Statistics - Methodology},
	annote = {Comment: 60 pages, 42 figures},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/TCZJ8HSF/Betancourt - 2018 - A Conceptual Introduction to Hamiltonian Monte Car.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/9QH68S2F/1701.html:text/html},
}

@book{ottinger_stochastic_1996,
	address = {Berlin, Heidelberg},
	title = {Stochastic {Processes} in {Polymeric} {Fluids}},
	isbn = {978-3-540-58353-0 978-3-642-58290-5},
	url = {http://link.springer.com/10.1007/978-3-642-58290-5},
	language = {en},
	urldate = {2021-11-04},
	publisher = {Springer Berlin Heidelberg},
	author = {Ãttinger, Hans Christian},
	year = {1996},
	doi = {10.1007/978-3-642-58290-5},
	file = {Ãttinger - 1996 - Stochastic Processes in Polymeric Fluids.pdf:/Users/soren/Zotero/storage/L7CQYNWG/Ãttinger - 1996 - Stochastic Processes in Polymeric Fluids.pdf:application/pdf},
}

@article{akiba_optuna_2019,
	title = {Optuna: {A} {Next}-generation {Hyperparameter} {Optimization} {Framework}},
	shorttitle = {Optuna},
	url = {http://arxiv.org/abs/1907.10902},
	abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
	urldate = {2021-11-05},
	journal = {arXiv:1907.10902 [cs, stat]},
	author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.10902},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 10 pages, Accepted at KDD 2019 Applied Data Science track},
	file = {arXiv Fulltext PDF:/Users/soren/Zotero/storage/IMDZ52PX/Akiba et al. - 2019 - Optuna A Next-generation Hyperparameter Optimizat.pdf:application/pdf;arXiv.org Snapshot:/Users/soren/Zotero/storage/WJQR88PW/1907.html:text/html},
}

@inproceedings{huang_densely_2017,
	address = {Honolulu, HI},
	title = {Densely {Connected} {Convolutional} {Networks}},
	isbn = {978-1-5386-0457-1},
	url = {https://ieeexplore.ieee.org/document/8099726/},
	doi = {10.1109/CVPR.2017.243},
	urldate = {2021-11-09},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q.},
	month = jul,
	year = {2017},
	pages = {2261--2269},
	file = {Submitted Version:/Users/soren/Zotero/storage/HT3JC7S5/Huang et al. - 2017 - Densely Connected Convolutional Networks.pdf:application/pdf},
}
